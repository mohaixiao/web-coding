### 软技能

#### 自我介绍一下？

面试官您好，我叫xxx，是成都信息工程大学软件工程大三的学生。今天来应聘贵公司的前端开发的岗位。

我在大二上的时候开始接触到前端，我的技术栈是react，我在知乎和绿盟科技的实习过一段时间。

在知乎分别主要负责To B的员工管理项目和面向运营开发的反作弊分析项目，

在这段实习中我认识到了合理封装组件的好处，以及性能优化和规范的工作流程的重要性。

在绿盟科技，我负责老项目的迭代开发，我学到了使用微前端进行新旧项目的混合开发的新理念。

同时我自己也开发了一个包括前台和后台的在线课程项目，这个项目比较好的亮点的话是

在登录方面我做了微信三方登录，短信校验，

在性能方面我做过SEO优化，图片压缩等一系列优化，

在用户体验上，我也尝试做了一个弹幕功能，

后台我就做了一个视频断点续传，数据收集上我也尝试了对用户的访问量和点击量、地域、来源的收集，并进行可视化的展示，同时我也封装了一个统一的表格组件和搜索组件。

除此之外，我也喜爱写博客文章，分享技术。我个人性格比较开朗，外向。

最后感谢面试官您抽出的宝贵时间。

#### 你为什么学前端？ 你怎么学前端的？

    大二开始网页设计课程接触前端页面开发，感觉前端简单的代码可以实现很炫酷的效果就开始学习前端了，后面工程实践也担任前端开发的角色，后面就一直坚持下来学习前端了。

    面对一个新的技术，我一般会找一个简短的入门视频建立起对他的基本认识，知道是干什么的，然后通过官方文档或者视频跟着做一些Demo实战，在做的过程中我就记录遇到的问题和心得发布到博客平台上，如果想要深入到话，我会看一些前端技术大佬的相关博客去深入学习他的原理。

#### 最近学了什么新技术，接触新技术，如何学习，了解过前端前沿技术吗（微前端，低代码）你对前端技术或者前端行业的发展有什么看法或者想法？你是否有在业余时间学习或者研究前端相关内容？

    最近了解了微前端，我找一个简短的入门视频建立起对他的基本认识，知道他是一种借用微服务根据业务划分模块的新的架构模式，然后通过官方文档或者视频跟着做一些Demo实战，了解了实现这种模式的不同技术方案，在做的过程中我就记录遇到的问题和心得发布到博客平台上。比如样式隔离，基本的项目搭建。

#### 未来的职业规划？

选择一个领域深入

精通基础知识：前端开发有很多基础知识，包括HTML、CSS和JavaScript等。首先要熟悉这些基础知识并且能熟练运用。
掌握框架和库：了解和掌握常用的前端框架和库，比如React和Vue.js等，可以提高你的工作效率和代码质量。
深入学习某一个方向：前端开发是一个非常广泛的领域，包括Web应用程序、移动应用程序以及桌面应用程序等。你可以选择其中的某个方向进行深入学习，并逐步成为专家。
学习后端开发知识：虽然前端开发主要涉及到客户端的开发，但是了解后端开发知识可以帮助你更好地与后端开发人员合作，提高工作协同效率。
参加技术会议和交流活动：参加行业内的技术会议和交流活动，可以结交志同道合的朋友，扩大自己的人际网络，还可以了解最新的技术趋势。
不断学习和更新知识：前端开发技术在不断更新和变化，要保持敏锐的观察力和学习能力，随时跟进最新的技术趋势。 

你在实习期间遇到的最大挑战是什么？你是如何解决的？你在实习期间完成了哪些具体的项目或任务？你在其中负责的部分是什么？你的成果和贡献是什么？

技术上：挑选上面项目难点，比如表单封装，hooks自定义。

业务上：多和产品，后端进行细致的沟通，很多时候好的沟通往往就是高效工作的保障。然后举例，比如和后端沟通接口返回的数据格式，直接根据后端返回的数据一步渲染表头，表体。和产品适当勇敢提出业务需求的不合理或者建议。

一个人独立的完成了产品交付的较大需求模块，主要负责绩效模块，反作弊模块粉丝分析，主要成果封装了通用的组件，和自定义hooks复用，大大提高了开发效率。

#### 你在实习期间使用了哪些前端技术和工具？你是如何学习和使用它们的？你的技能水平如何？

学习了基本的联调，测试，部署流程。以及基本的git协作。

## 实习+在线教育项目

### 提交代码用 git merge 多还是用git rebase 多，2者有什么区别，多人协作开发时，开发流程是什么样的，常用的git 命令是什么，知道哪些企业级分支管理策略，优缺点？

#### git merge 多还是用git rebase

git merge 会让2个分支的提交按照提交时间进行排序，并且会把最新的2个commit合并成一个commit。最后的分支树呈现非线性的结构

git reabse 将dev的当前提交复制到master的最新提交之后，会形成一个线性的分支树

#### 多人协作开发时，开发流程是什么样的，常用的git 命令是什么

- 多人协作开发，就不能使用`master`分支了，而是要每个开发者单独拉一个分支，使用`git checkout -b <branchname>`，运行`git branch`可以看到本地所有的分支名称。
- 自己的分支，如果想同步`master`分支的内容，可运行`git merge master`。切换分支可使用`git checkout <branchname>`。
- 在自己的分支上修改了内容，可以将自己的分支提交到远程服务器
- 最后，待代码测试没问题，再将自己分支的内容合并到`master`分支，然后提交到远程服务器。

#### 知道哪些企业级分支管理策略，优缺点?

回答知乎那套  

### http 握手、TCP、UDP的区别，HTTP 1 2 3的区别，你能讲一下dns 吗？dns 域名解析发的包是 tcp 还是 udp ？

#### http 握手

https://www.bilibili.com/video/BV1kV411j7hA/?spm_id_from=333.337.search-card.all.click&vd_source=037b856144283671f89f562ed7eeb263

#### TCP、UDP的区别

**TCP 和 UDP 区别：**

*1. 连接*

- TCP 是面向连接的传输层协议，传输数据前先要建立连接。
- UDP 是不需要连接，即刻传输数据。

*2. 服务对象*

- TCP 是一对一的两点服务，即一条连接只有两个端点。
- UDP 支持一对一、一对多、多对多的交互通信

*3. 可靠性*

- TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按序到达。
- UDP 是尽最大努力交付，不保证可靠交付数据。但是我们可以基于 UDP 传输协议实现一个可靠的传输协议，比如 QUIC 协议，具体可以参见这篇文章：[如何基于 UDP 协议实现可靠传输？(opens new window)](https://xiaolincoding.com/network/3_tcp/quic.html)

*4. 拥塞控制、流量控制*

- TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。
- UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。

*5. 首部开销*

- TCP 首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 `20` 个字节，如果使用了「选项」字段则会变长的。
- UDP 首部只有 8 个字节，并且是固定不变的，开销较小。

*6. 传输方式*

- TCP 是流式传输，没有边界，但保证顺序和可靠。
- UDP 是一个包一个包的发送，是有边界的，但可能会丢包和乱序。

*7. 分片不同*

- TCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要传输丢失的这个分片。
- UDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层。

**TCP 和 UDP 应用场景：**

由于 TCP 是面向连接，能保证数据的可靠性交付，因此经常用于：

- `FTP` 文件传输；
- HTTP / HTTPS；

由于 UDP 面向无连接，它可以随时发送数据，再加上 UDP 本身的处理既简单又高效，因此经常用于：

- 包总量较少的通信，如 `DNS` 、`SNMP` 等；
- 视频、音频等多媒体通信；
- 广播通信；

#### 你能讲一下dns 吗？dns 域名解析发的包是 tcp 还是 udp ？

DNS使用UDP协议是因为UDP具有较低的开销和相对较高的性能，适合用于快速的域名解析查询。

UDP是一种面向无连接的传输协议，它不提供可靠的数据传输和错误恢复机制，但在DNS解析中，这些功能并不是非常关键。DNS查询通常是简短的请求和响应过程，UDP可以满足实时性要求，同时减少了传输的开销。

在某些情况下，当DNS响应超过DNS报文的大小限制时，会使用TCP协议代替UDP进行域名解析。TCP是一种面向连接的传输协议，具有可靠性和流控制等特性，适用于大型的DNS查询或特殊情况下的域名解析。

总结起来，绝大多数的DNS域名解析使用UDP协议，仅在需要传输大型响应或特殊情况下才会使用TCP协议。

### 浏览器原理，地址栏输入一个地址会发生什么？

### react 原理，大概说一下React Router的原理

### 如何优化的表单效率，封装form 组件你会考虑哪些问题

简单介绍一下员工内部管理系统？，你在实习过程中印象最深刻的项目是哪一个，难点是什么，如何解决的

这个项目主要是用于内部员工的管理，我负责的是绩效模块，用于员工对自己绩效的查看申诉和管理人员对员工绩效的创造等等。

其中绩效方案是一个比较复杂的表格嵌套表单，涉及到不同的公式配置等6个表单。由于涉及表单新建，编辑等不同状态下差异性置灰和样式布局（**背景**） ，如果是不封装就必须根据不同的表单类型来重新写一套colums来设置不同的disabled属性（**为什么封装**）。于是我自己封装了实现了一个可自定义布局和验证的表单面板组件，并提供了一些方便的方法来操作表单字段。一套代码展示不同类型表单的效果，以及表单的通用默认布局。**（结果）**

#### 那说一下你是怎么封装通用表单组件的？如何优化的表单效率,封装form 组件你会考虑哪些问题

首先根据业务需要表单的类型以及置灰等等业务需求。

1. 首先我使用了Context来存储表单的类型将From组件包裹，通过Context.Provider来将表单类型传递给子组件，确认表单是编辑，新建还是详情状态。

2. 然后我使用了`useImperativeHandle`钩子来暴露一些表单操作方法，例如`setFieldsValue`、`validateFields`、`resetFields`、`isFieldTouched`和`getFieldValue`等。也给组件的props包括表单类型（type）、子元素（children）、布局（layout）、表单项布局（formItemLayout）、标签对齐方式（labelAlign）和是否禁用（disabled）等设置了默认值。

3. 最后，组件使用forwardRef函数来将CommonFormPanel组件转发为一个可使用ref的组件，以便在父组件中使用上述暴露的表单操作方法。

#### 为什么用context，为什么不直接用枚举类型表示表单的状态，直接父子组件传参？

我选择使用 Context 的目的是为了有变量可以存储表单的状态，是否置灰等等，避免在父子组件之间频繁传递状态，特别是在多层嵌套的情况下。而且这种方式可以使通用表单组件更具通用性，更加具有扩展性，保证了以后需要添加嵌套表单类型状态的时候也可以扩展。就好比之前新增和修改表单会存在是否复现数据的情况，我添加了表单状态，后面部分地方添加了查看功能又需要置灰，我可以直接添加一个表单的状态值，只需要动配置的地方的代码，如果使用枚举类型来表示表单状态，那么在多个组件之间传递时需要手动管理状态，会导致代码冗余和维护困难。数据流不是很清晰，同时，使用 Context 还可以更好地支持复杂场景下的共享状态，比如组件库中可能存在多个表单组件或者子组件嵌套的情况。因此，使用 Context 是更加优秀的方案。

当面试官追问如何设计表单状态时，我可以进一步说明，如果状态比较简单并且只有一个组件会用到，枚举类型也是一个可选方案，但是当组件的逻辑复杂或者状态需要在多个组件之间共享时，使用 Context 更加的优秀，而且不会破坏 React 数据流的特性。最后，我可以解释使用 Context 的具体实现方式，以及它的优缺点。

#### 为什么不直接使用form的disabled属性进行置灰，如何实现差异化置灰效果的？

因为新建，编辑，查看的页面有着不同的置灰要求，并且还可以根据勾选框进行取消置灰，直接给Form组件本身增加disabled属性会导致置灰不完全，比如input输入框（**why**）于是使用context为表单设置表单类型状态包裹Form组件。（**how**）这里是Table和Form组件配合使用，通过表单类型和动态化columns可以通用一套columns，也实现在columns里面为input输入框设置置灰，减少代码量，（**what**）

#### 使用antd Form和Table组件嵌套的时候，为什么直接给Form组件本身增加disabled属性会导致置灰不完全，比如input输入框？

这是因为antd的Form组件的disabled属性仅仅是将整个Form表单的字段都设置为disabled状态，它并不会作用到Form内部的子组件，比如input输入框。所以，直接给Form组件本身增加disabled属性会导致只有表单字段被禁用，而子组件不会受影响。

解决这个问题的方法是，在 Form 组件内通过 API 设置表单项的 `disabled` 属性，而不是直接在 Form 组件本身设置。比如可以使用 `Form.Item` 组件包装每个表单项，然后在 `Form.Item` 组件上设置 `disabled` 属性，这样就只禁用了单个表单项，而保持了其他表单项的正常状态。

#### 表单自定义校验写过吗？

我使用validator表单自定义校验，主要是进行后端接口查重等

```js
<Form.Item
  label={label}
  name="name"
  validateTrigger={type === 'edit' ? [] : ['onBlur']}
  validateFirst
  rules={[
    { required: true, message: '请输入业务名称' },
    { max: 20, message: '20字以内' },
    {
      validator: async (_, value: string) => {
        const {
          data: { exist },
        } = await isBusinessClassifyNameExist({ name: value });
        if (exist) {
          return Promise.reject();
        }
        return Promise.resolve();
      },
      validateTrigger: 'onBlur',
      message: '业务名已存在',
    },
  ]}
>
  <Input placeholder="20字以内"></Input>
</Form.Item>
```

#### 我们什么时候会使用ref，你的标准是什么

在 React 中，ref 是操作 DOM 的一个重要手段，用于获取组件实例或访问 DOM 元素。一些情况下我们需要直接操作或者访问 DOM 元素，比如：

- 获取某个组件内部的 DOM 元素，从而更精确地控制组件的行为和样式；
- 在表单中获取输入框的值、焦点及其他相关信息；
- 对于一些第三方库的组件，无法通过 props 直接操作它暴露的样式和属性，在这种情况下，我们可以使用 ref 定位它的 DOM 节点，然后通过 DOM API 直接操作它。

我的标准是，只在必要时使用 ref，因为过多地使用 ref 将打破 React 的数据流动一致性，并且可能使代码更难维护和测试。一般来说，我们可以使用 state 和 props 来管理组件的行为和状态，而不需要使用 ref，只有在必要时才使用它，这样可以保持代码的清晰和可维护性。同时，我也会避免过多地嵌套 ref，以避免组件树的深度和性能问题。

比如我在实现弹幕效果时，我就使用了`useImperativeHandle`搭配ref绑定Player暴露给父组件子组件方法，   在播放时机实例化player对象。 

#### 那你说一下Form 组件 fields 的值的传递原理？

**原理**其实是使用了Context，有一个传递 form 对象的 context，Form 组件往其中设置值，Item 组件在根据name设置的路径去取其中的部分值。

Form.Item 会给子组件传入 value、onChange 参数用来设置值和接受值的改变，同步到 form 的 fields。form 对象通过 Provider 放到了 FieldContext，fieldContext 里就有 getFieldsValue、setFieldsValue 等 form 对象的方法了，antd 的 Form 通过 FieldContext 保存了 form 对象，在 FormItem 组件里取出 FieldContext，并根据 namePath 取出对应的值，传递给子组件。这就完成了 form 的 field 值的设置。

除了 FieldContext 外，还有很多别的 Context，比如 size、disabled 等都是通过 context 存储和传递的。

#### 在 Ant Design 表单中避免持续收集 `onChange` 和 `value`

如果您希望在 Ant Design 表单中的 `onChange` 事件中只收集最新的值，而不是每次都收集所有的值，可以使用 Ant Design 提供的 `setFieldsValue` 方法来手动更新表单字段的值。

下面是一个示例代码，展示如何在 Ant Design 表单中避免持续收集 `onChange` 和 `value`：

```js
import React, { useState } from 'react';
import { Form, Input, Button } from 'antd';

const CustomForm = () => {
  const [form] = Form.useForm();
  const [name, setName] = useState('');

  const handleNameChange = (e) => {
    setName(e.target.value);
    form.setFieldsValue({ name: e.target.value });
  };

  const onFinish = (values) => {
    console.log('表单提交的值：', values);
  };

  return (
    <Form form={form} onFinish={onFinish}>
      <Form.Item name="name" label="姓名">
        <Input value={name} onChange={handleNameChange} placeholder="请输入姓名" />
      </Form.Item>

      <Form.Item>
        <Button type="primary" htmlType="submit">提交</Button>
      </Form.Item>
    </Form>
  );
};

export default CustomForm;
```

在上述代码中，我们利用了 React 的 `useState` 来保存姓名字段的值。在 `handleNameChange` 函数中，通过 `setName` 更新 `name` 的值，并使用 `form.setFieldsValue` 方法将最新的值同步到表单字段中。

这样，在表单提交时，只会收集到最新的字段值，并避免持续收集 `onChange` 和 `value`。

请注意，我们使用了 `Form.useForm` 来创建表单实例，并将其传递给 Form 组件的 `form` 属性。

通过以上的方法，您可以在 Ant Design 表单中避免持续收集 `onChange` 和 `value`，只保留最新的值。

#### context 的原理呢？

createCotnext 就是创建了一个 _currentValue、Provider、Consumer 的对象。

_currentValue 就是保存值的地方

react 渲染的时候会把 jsx 编译成 render function，然后执行之后就是 vdom，然后 vdom 会经历 reconcile 过程转为 fiber 结构，转完之后一次性 commit，也就是更改 dom。这种 Provider 类型的 vdom 自然会转为对应的 fiber 节点，在 reconcile 的时候会做单独的处理：

Provider 是一种 jsx 类型，之后会转为对应的 fiber 类型，然后它的处理就是修改 _currentValue，也就是修改 context 值。

Consumer 和 useCotnext 就是读取 _currentValue，也就是读取 context 值。

唯一要注意的是 Provider 处理每个节点之前会入栈 context，之后处理完这个 fiber 节点会再 pop 出栈，然后恢复 context，这样就能保证 context 只影响子组件。

[React Context 实现原理：它在 antd 源码里简直用的太多了 - 掘金](https://juejin.cn/post/7200002468460806205)

#### 说说对React中context的理解，有可替代方案（Dva等）吗？

React 中的 context 是一种跨组件层级传递数据的方式。它可以让父组件向子组件传递数据，而无需在每一个子组件中显式地通过 props 的形式传递数据。Context 可以被看作是组件树上的全局变量。

使用 Context 时，我们定义一个 Context 对象，可以通过 React.createContext 方法创建。Context 对象中包含两个组件：Provider 和 Consumer。Provider 用于设置 Context 的值，Consumer 用于获取 Context 的值。当 Context 值发生改变时，所有使用该 Context 的组件都会自动更新。

Dva 是一个类 Redux 的应用框架，提供了更多的约定和自动化的流程，以简化 Redux 的使用，并添加了一些额外的功能和插件。在 Dva 中，可以使用 Model 中的 state 来解决跨组件传递数据的问题，这类似于使用 Redux 中的 Store 来管理数据。在 Model 中保存的数据可以被整个应用中的组件共享和访问，而无需使用 Context 或 props 进行传递。

相较于使用 Context，Dva 可以更好地解决组件层级嵌套较深时，Context 数据传递行为变得复杂难以理解的问题。但 Context 也有自己的优点，例如，它可以更加灵活地传递数据；它是 React 自带的 API，无需引入额外的依赖，并且可以与 React 官方的工具协同工作。

因此，在实际使用中，我们需要根据具体场景来选择合适的数据传递方案。在数据传递行为简单的场景下，Context 能够带来极大的便利；而在数据传递行为复杂且需要更完整状态管理的场景下，Dva 的使用可能更适合。

#### 简单介绍一下反作弊系统

这是一个给运营，产品使用的反作弊系统，我负责开发用户粉丝分析工具这块，主要是进行对不同用户的粉丝行为进行数据可视化的展示，目标是通过新版分析可以快速判断用户刷粉作弊情况，节省运行成本。

在这个项目由于存在大量图表，请求大量数据服务器压力大 **（背景）**，我在请求时机和请求次数上做了适当的处理，切换组件时进行了缓存组件，首屏渲染时只进行基本的用户信息和粉丝行为图表的请求，其他详细的行为图表，都在拉动互动指标数据表区间，才进行请求 **（选择解决方法）**。

#### 那说一下你怎么解决后端压力的？（慎重）

减少请求次数 + 使用组件缓存

首次进入时，如果url上有查询信息，直接触发查询使用（useEffect监听，useSearchParams）来决定现在是否直接发起请求，以及查询请求只会触发基本不改动的信息，频繁改动的信息使用一个`trigger`变量控制。

使用Antd的Tabs`destroyInactiveTabPane={false}`来缓存不同的图表组件。并且为了数据的方便使用和维护，都在整个模块index入口文件使用context向子组件传递属性和回调函数。

#### Antd组件里面Tabs缓存组件的原理？

Antd 的 Tabs 组件里的 `destroyInactiveTabPane` 属性设置为 `true` 后，代表标签页无需每次切换时都重新渲染。此时，如果多次切换同一个标签页，前一次渲染出的组件不会被卸载，而是被缓存（保留 DOM 状态）。

底层实现原理是在 Tabs 组件中引入了 `rc-tabs` 基础包。在 `rc-tabs` 中，每次切换标签页后，会将要隐藏的标签页销毁（已完成 unmount），将要显示的标签页进行渲染和显示。

当 `destroyInactiveTabPane` 属性设置为 `false` 时，`rc-tabs` 会将将要隐藏的标签页进行卸载，而不是销毁，卸载后的标签页会被缓存。在下一次再次切换到该标签页时，会将卸载前的缓存重新挂载（remount）到 DOM Tree 中。

这种缓存组件的方式，可以提高标签页切换的性能，但是需要注意在卸载组件时，需要手动清理组件的定时器或绑定的事件等，否则可能会造成内存泄漏问题。同时也需要注意，如果缓存的组件本身拥有过多或占用过多内存，这种缓存方式可能会对网页性能造成不良影响。通常建议仅在组件轻量、易用、反复使用并且占用内存较小的情况下使用此项特性。

#### 使用自定义hooks，减少繁杂的echarts配置，描述一下你是怎么自定义hooks的？

这段代码是一个自定义 React Hook，用于获取 echarts 图表的系列配置选项。该 Hook 接受以下参数：

url：表示数据请求的 URL 地址。

params：表示数据请求的参数。

trigger：表示是否触发数据请求。

seriesOptions：表示 echarts 图表系列的配置选项，默认为一个饼图的配置选项。

在 Hook 内部，首先定义了一个 fetchChartData 函数，用于发送数据请求。该函数使用 request 方法发送 GET 请求，并将请求参数作为 URL 参数传递。

然后使用 useRequest 钩子来发送数据请求，并将请求结果保存在 data 变量中。在使用 useEffect 钩子监听 params 和 trigger 变量的变化，当 trigger 变量为 true 时，调用 run 方法发送数据请求。

最后，根据请求结果，将每个数据项转化成 echarts 系列配置选项中的 data 属性，并按照数值大小排序。最终返回一个包含 chartSeriesData 属性的对象，该属性包含了 echarts 系列的配置选项。

由于图表大多数配置是默认不变的，主要改变的是`series`配置项里面的data因此我自定义的Hook，主要用于发送数据请求（在使用 `useEffect` 钩子监听 params 和 trigger 等传递的变量的变化，当 trigger 变量为 true 时，调用 run 方法发送数据请求）。根据请求结果，将每个数据项转化成 echarts 系列配置选项中的 data 属性，并按照数值大小排序。然后将数据进行加工排序，在合并默认设置的echarts 系列的 **seriesOptions** 配置选项返回出去。这样在请求数据时直接可以获得默认好的 **series配置项** 数据，并且配合封装的图表组件（已经设置有默认的baseOptions）实现控制数据推动图表展示改变，通过自定义 Hooks，我们可以将 Echarts 初始化和配置分离出来。

传入请求url，parmas -> 获得带有data数据的配置项，在配合好封装的线图，饼图等等，在不需要使用默认series配置项的时候就解构用data即可，需要使用时就直接使用默认series配置项。

#### 简单说一下你是怎么封装的通用图表组件？

对于不同的图表类型分别封装了通用饼图，曲线图。上面封装的hooks就是返回的 **series配置项，** 于是基本的图表组件就是封装的**基本配置项baseOptions。同时我也是使用了useMemo来进行配置计算处理的处理的**

对于曲线图，由于业务需要展示不同时间量级的图表，封装组件我使用series配置项和x轴数据，默认选择项等等是外部动态传递来实现。

#### 你对封装组件的理解？

根据业务需求来进行组件的封装，目的就是提高代码复用性，降低代码耦合度以及提高代码的可维护性的方式。将一些独立的、可复用的功能封装成一个组件，并暴露一些对外的接口，以供其他地方使用。具体来说，封装组件可以达到以下几个目的：

1. **复用性**：将一些相对独立的功能封装成一个组件，可以有效地提高这些功能的复用性，降低代码的重复度。

2. **封装参数**：通过参数传递的方式，可以在一个组件中封装不同的配置和数据，使得同一组件能够呈现出不同的功能和样式。

3. **解耦**：通过一个明确定义的接口，可以将组件与其他组件或业务逻辑代码解耦，使得修改组件不会影响其他代码的正常运行。

4. **易维护**：将各种功能进行封装，可以降低代码的复杂度，减少代码的冗余，提高代码的可维护性。

5. **易测试**：通过测试封装的组件可以有效地对组件的功能和 API 进行测试，减少代码测试的难度和成本。

### 数据可视化大屏你们用的什么技术？echarts了解过吗，Echarts了解到什么程度，底层是用canvas和re-render

### 微前端

微前端的原理是什么，如果让你开发一个简单的微前端，大概需要做哪些事情。

你们的微前端是怎么做的，用的什么框架，什么场景需要用微前端。

项目用这个微前端框架的优势和劣势。

你们微前端用的什么框架，知道几个主流的微前端框架的区别吗？

能讲一下巨石模块吗？为什么会存在巨石模块，是一开始设计就有问题吗？

你们项目用微前端是怎么解决问题的，为什么不用 iframe？或者 webpack 5 模块联邦，而是采用  qiankun？（或者你可能采用别的） 如果是你做技术选型，你会怎么做，为什么？

### 技术选型需要考虑哪些地方

### 弹幕模块

#### 如何开发弹幕的动效

添加弹幕就是直接进行接口调用然后推送页面，手动选择进度，清空之前的弹幕，在根据时间请求之后的弹幕。切换到下一集也清空弹幕。在视频播放的时候都进行弹幕轮训请求。在这里我进行轮训的时候也遇到了useEffect闭包的问题。因为传递的集数是props，在定时器里面每次都没有更新最新，拿到的弹幕还是老旧的弹幕。然后我是参考了ahooks里面的useLatest将props集数进行ref存储解决的。

在使用 React 的 useEffect 钩子时，经常会遇到闭包问题。当 useEffect 依赖项发生变化时，新增的 effect 函数会使用闭包中最新的状态或变量值，而不是 effect 创建时的状态或变量值。

然而，ahooks 库中的 useLatest 可以帮助解决这个问题。useLatest 是一个自定义的 Hook，它接受一个初始值，并返回一个可变的 ref 对象。

useLatest 的原理是：

1. 在内部，它使用 useRef 创建了一个 ref 对象来保存传入的初始值。
2. 返回一个对象，对象中有一个 current 属性，初始值为传入的初始值。

通过使用 useLatest，可以将需要保持最新引用的值存储在 ref 对象的 current 属性中。在 effect 函数中，可以通过访问 ref.current 来获取该值，而不是通过闭包访问。

这样做的好处是：

1. 解决了闭包问题，确保了在 effect 函数中获取的值始终是最新的值。
2. 在某些场景下，例如处理异步请求的回调函数中，可以保证获取到的值是请求发起时的值，而不会因为更新而发生变化。

#### 在弹幕模块的自定义Hooks中，您都实现了哪些功能？请提供一些具体的示例，以展示您的自定义Hooks是如何工作的

我主要封装了socket的监听和推送，以及将监听接受到的弹幕存储到数组里面。

```js
/**
 * 弹幕逻辑配置
 */
import { useRef, useState } from "react";
import { io } from "socket.io-client";

const useSocket = () => {
  // 弹幕实例变量名
  const socket = useRef<any>(null);
  // 发送的弹幕
  const videoDanmuList = useRef<any[]>([]);

  const initialize = () => {
    // 建立传输链接 http://127.0.0.1:8081
    socket.current = io("ws://127.0.0.1:8081");
    socket.current.on("connect", () => {
      console.log("socketio已连接");
    });
    onBulletChat();
  };

  // 发送弹幕事件
  const handleAddDanmu = (data: any) => {
    socket.current.emit("bulletChat", data);
  };

  // 监听bulletChat事件
  const onBulletChat = () => {
    socket.current.on("message", (data: any) => {
      videoDanmuList.current.push(data);
    });
  };

  return {
    videoDanmuList,
    initialize,
    handleAddDanmu,
    onBulletChat,
  };
};

export default useSocket;
```

#### Redis发布订阅（Pub/Sub）是如何用于实现分布式WebSocket的？请解释一下这一部分的架构和工作原理，项目中是如何处理不同服务器之间的弹幕通讯的？

多个服务器订阅一台redis

 io弹幕事件接收-> redis 推送 -> redis 接受 -> io 弹幕事件推送

#### 您可以描述一下在多服务器环境中是如何确保弹幕消息在各个服务器之间同步的。

使用发布订阅模式

#### websocket握手是怎么实现的？知道他的心跳机制吗,websocket报文格式,websocket可以多路复用吗,为什么http2可以多路复用,websocket不行。

WebSocket握手是通过HTTP协议发起的一种特殊握手过程。下面是WebSocket握手的基本步骤：

1. 客户端发送一个HTTP请求，其中包含了Upgrade头部字段，值为"websocket"，并且还包含了Connection头部字段，值为"Upgrade"。
2. 客户端还需要生成一个随机的Sec-WebSocket-Key头部字段，该字段的值是经过Base64编码的随机字符串。
3. 服务端收到客户端的请求后，会进行一些验证，例如校验Upgrade和Connection等头部字段的正确性。
4. 如果验证通过，服务端需要返回一个HTTP响应，状态码为101（Switching Protocols）。响应中也包含Upgrade和Connection头部字段。
5. 服务端同样需要生成一个Sec-WebSocket-Accept头部字段，该字段的值是将客户端发送的Sec-WebSocket-Key加上一个特殊的GUID（"258EAFA5-E914-47DA-95CA-C5AB0DC85B11"）进行SHA1哈希计算后，再进行Base64编码得到的结果。
6. 客户端收到服务端的响应后，会进行验证，检查Sec-WebSocket-Accept字段是否正确，如果验证通过，表示握手成功。
7. 握手成功后，连接从HTTP协议切换到WebSocket协议，双方可以开始进行实时通信。

关于WebSocket的心跳机制，WebSocket定义了一种称为Ping/Pong的心跳机制。它允许客户端或服务端发送Ping帧，对方收到后需要回复一个Pong帧，以保持连接的存活状态。Ping/Pong帧不包含实际的应用数据，仅用于检测连接的可用性。

当一方发送Ping帧时，对方必须尽快回复一个对应的Pong帧。如果一定时间内没有收到Pong帧，就可以判断连接出现问题，并进行相应的处理，例如关闭连接或重新建立连接。

Ping/Pong心跳机制可以在网络不稳定或长时间闲置的情况下，及时发现并处理连接异常，提高连接的可靠性。

HTTP/2可以实现多路复用，而WebSocket本身并不支持多路复用。

HTTP/2是一种二进制协议，它引入了一项重要的特性——多路复用（Multiplexing）。多路复用使得在单个TCP连接上能够同时发送多个HTTP请求和接收多个响应，而无需为每个请求/响应建立新的TCP连接。这样可以显著减少延迟和提高网络效率，特别适用于大量小型请求的场景。

在HTTP/2中，每个请求和响应都被分割成称为帧（Frame）的小块，这些帧可以交错地发送和接收。每个帧都包含一个标识，标识了它所属的流（Stream），而流则对应着一个具体的请求或响应。通过对帧的组织和发送顺序的管理，HTTP/2能够在单个TCP连接上同时处理多个流，实现了多路复用。

相比之下，WebSocket是一种全双工的通信协议，它基于HTTP协议进行握手后，升级为WebSocket连接。WebSocket连接通过与服务器的长连接，在客户端和服务器之间实现了双向的实时通信。然而，WebSocket协议本身并没有提供多路复用的机制。

一个WebSocket连接只能支持单一的数据流传输，也就是说，在一个连接上只能发送一个请求或接收一个响应。如果需要同时进行多个独立的数据传输，就需要建立多个WebSocket连接。

需要注意的是，虽然WebSocket本身不支持多路复用，但可以通过在应用层进行协议设计和实现，来模拟多路复用的效果。比如，在一个WebSocket连接上，可以通过定义自己的消息格式或协议规范，将多个数据流区分开来，并在应用层进行数据的交互和处理。

总结来说，HTTP/2支持多路复用是因为它是基于二进制帧的协议，通过管理帧的组织和发送顺序，实现在单个TCP连接上同时处理多个流。而WebSocket协议本身并没有提供多路复用的机制，但可以通过应用层协议设计和实现来模拟多路复用的效果。

#### 设计模式了解吗？我看你在弹幕模块采用发布订阅模式，你能给我讲讲吗？它跟观察者模式有什么区别？为什么当时想到用发布订阅实现这个功能，你觉得这个方案存在什么劣势？

### pv、uv 埋点有了解吗，如何计算的？

PV表示页面访问量，UV表示独立访客数，我是设计了一个用户访问的表，收集用户的ip，来源，设备类型user_agent组成一个表，pv就统计条数，uv就按照用户的ip+设备的唯一值计算。然后在不同页面上挂在调用接口。

**PV（页面访问量）**：PV表示页面访问量，它反映了网站或应用的页面被访问的次数。每当一个页面被加载或刷新，PV都会增加。计算PV的方法很简单，只需累加每个页面被访问的次数即可。

**UV（独立访客数）**：UV表示独立访客数，它反映了网站或应用的不同访客数量，每个访客只计算一次，无论他们访问了多少个页面。计算UV通常需要使用一些技术手段来区分不同的访客，例如通过使用Cookie、用户账号、IP地址等。因为UV的计算涉及用户隐私和数据收集，所以需要谨慎处理。

计算PV和UV的方法可以用以下示例来说明：

假设有一个网站，一天内的访问记录如下：

- 用户A访问了页面X、页面Y、页面Z。
- 用户B访问了页面X、页面Y。
- 用户C访问了页面X、页面Z。
- 用户D访问了页面Y、页面Z。

计算PV和UV：

- PV：页面X被访问了4次（用户A、用户B、用户C、用户D），页面Y被访问了3次，页面Z被访问了4次。所以总PV为4+3+4=11。
- UV：有4个不同的访客，分别是用户A、用户B、用户C、用户D，所以总UV为4。

注意：UV的计算通常在一定时间范围内，例如一天、一周或一个月内计算，以确定特定时间段内的独立访客数量。PV则是对所有页面访问次数的累加。

### 断点续传

#### 断点续传如何做， http 对应的 code 码是多少,断点续传的原理是什么？

#### 我看到你讲到断点续传，你怎么实现的？为什么使用断点续传，除此之外你还有想过其他方案吗？能用分片上传吗？如果你用分片上传你需要考虑什么问题？

简单来说就是把一个大的文件切割为一个个片段然后依次传递给后端，全部上传完毕之后，后端就把这些片段给拼接起来。考虑到网络情况不稳定的情况下上传时间会变长，高频次文件上传失败，失败后又需要重新上传等等，于是就选择了断点续传的解决方案。

我在项目中具体的实现呢就是，先在前端设置一个对象保存我们要上传的文件的基本信息，就比如需要的视频格式，hash值，文件大小，上传字段这些，然后呢就会根据文件hash（使用FileReader对象将文件内容进行读取，视作ArrayBuffer在转换为hash字符串）等等信息去向后端查询之前是否上传过，拿到最新的上传字节数。然后根据这个字节数和文件大小来具体的判断上传是否完成，要是没有完成，那就根据根据已经上传了的字节数作为开始来切割一段文件，然后继续上传（使用表单的格式 ）给后段。然后一直根据后端返回的最新上传的字节数来判断是否还要继续上传，上传过程中将文件在服务器写为临时文件，等全部写完了（文件上传完），将此临时文件重命名为正式文件即可，那么就可以进行华为云的视频上传了。当然根据后端返回的code码如果不为0就确认上传失败就得把前端本地存储的上传进度给归零了。

和断点续传类似的方案还有分片续传，他们都是将大文件切割为小文件。他们区别主要是上传方式上有些区别，一个可以是可以并行，按顺序上传。一个是下次上传的时候从中断的地方继续上传，如果使用分片上传可能得考虑上传片段的顺序，决定每个分片的大小。分片过小可能导致过多的HTTP请求和上传过程中的高延迟，分片过大可能导致内存和网络问题。

但是基于断点续传可以续传这个功能我还是选择了断点续传这个方案。

它们有以下主要区别：

1. **上传方式：**
   
   - **分片上传：** 在分片上传中，文件被分成较小的块（分片），然后逐个上传这些分片。这些分片可以按顺序上传，也可以并行上传。一旦所有分片上传完成，服务器可以将它们组装成完整的文件。
   - **断点续传：** 断点续传是指用户可以在文件上传过程中中断，然后再次从中断的地方继续上传，而不是从头开始上传整个文件。通常，这需要在客户端和服务器端记录上传进度以及文件状态。

2. **应用场景：**
   
   - **分片上传：** 适用于上传大型文件，因为它可以减少上传失败的风险。它通常用于需要高效、稳定上传的场景，如视频上传、大型数据文件上传等。
   - **断点续传：** 主要用于处理网络不稳定或上传时间较长的情况。它允许用户在上传中断后恢复，无需重新上传整个文件。

3. **实现复杂性：**
   
   - **分片上传：** 分片上传通常更复杂，因为它涉及将文件分成块、管理分片的顺序和完整性、分片上传并发等问题。
   - **断点续传：** 断点续传相对较简单，因为它主要关注如何记录和恢复上传进度。

4. **性能和效率：**
   
   - **分片上传：** 分片上传可以提高上传的效率，因为它允许并行上传多个分片，减少了上传大文件时的延迟。
   - **断点续传：** 断点续传主要用于提高可靠性，而不是性能。它确保即使在上传中断后，用户也可以继续上传。

5. **服务器支持：**
   
   - **分片上传：** 服务器需要支持接收和处理分片上传请求，并能够组装分片成完整文件。
   - **断点续传：** 服务器需要支持记录和恢复上传进度的功能。

### 如何实现的图片懒加载，图片懒加载的原理与简单实现

首先就是使用一个`bat-sharp`插件将图片都转为`webp`格式，然后依次上传到OSS服务器。

然后我封装一个组件，将图片img标签使用的本地路径修改为对应的cdn链接。这样就不要改变之前使用本地图片路径的地方并且给img标签直接使用`loading="lazy"`，大多数浏览器支持这个属性，在页面滚动时以懒加载（Lazy Loading）的方式加载图片，以提高页面性能和加载速度。当然如果想要更精确的去控制加载的时机，还是可以使用监听滚动事件，也可以使用`Intersection Observer`进行监听。

![](/Users/mohaixiao/Library/Application%20Support/marktext/images/2023-08-22-19-35-09-image.png)

### 手写懒加载+CDN

CDN 是基于 DNS 的，在权威域名服务器做了 CNAME 的转发，然后根据请求 IP 的所在地来返回就近区域的服务器的 IP。

```js
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Document</title>
  </head>
  <body>
    <div class="container">
      <img src="user.jpg" data-src="user.jpg" />
      <img src="user.jpg" data-src="user.jpg" />
    </div>
  </body>
</html>

<script>
  var imgs = document.querySelectorAll("img");
  function lozyLoad() {
    var winHeight = window.innerHeight;
    for (var i = 0; i < imgs.length; i++) {
      if (imgs[i].getBoundingClientRect() < winHeight) {
        imgs[i].src = imgs[i].getAttribute("data-src");
      }
      console.log("scroll 触发");
    }
  }
  window.onscroll = lozyLoad;
</script>

<script>
  const images = document.querySelectorAll("img");
  const callback = (entries) => {
    entries.forEach((entry) => {
      if (entry.isIntersecting) {
        const image = entry.target;
        const data_src = image.getAttribute("data-src");
        image.setAttribute("src", data_src);
        console.log("触发");
      }
    });
  };

  const observer = new IntersectionObserver(callback);
  images.forEach((image) => {
    observer.observe(image);
  });
</script>
```

```js
import React, { useRef, useEffect, useState } from 'react';

function LazyImage({ src, alt }) {
  const imgRef = useRef(null);
  const [loaded, setLoaded] = useState(false);

  useEffect(() => {
    const observer = new IntersectionObserver(
      (entries) => {
        entries.forEach((entry) => {
          if (entry.isIntersecting) {
            // 图片进入视口
            const img = new Image();
            img.src = src;
            img.onload = () => {
              // 图片加载完成后设置src属性
              if (imgRef.current) {
                imgRef.current.src = src;
                setLoaded(true);
              }
            };
            observer.unobserve(imgRef.current); // 只加载一次
          }
        });
      },
      { threshold: 0.5 } // 当图片至少50%进入视口时触发加载
    );

    if (imgRef.current) {
      observer.observe(imgRef.current);
    }

    return () => {
      if (imgRef.current) {
        observer.unobserve(imgRef.current);
      }
    };
  }, [src]);

  return (
    <img
      ref={imgRef}
      src={loaded ? src : ''}
      alt={alt}
      style={{ opacity: loaded ? 1 : 0 }}
    />
  );
}

export default LazyImage;
```

### 说说微信登录的流程与支付的流程,我看你实现了简化用户登录，是交互层面的优化还是技术层面的优化呢？技术优化你是如何实现的？有做过验证，具体快了多少？

登录流程就是服务器给微信服务器一个授权接口，服务器拿到access_token调取微信的接口去获取ticket，拼接出二维码链接。并且在redis设置带有登录或者注册的type+ticket 存储isScan为false，在前端扫码之后，微信会使用授权的api回调，传递ticket+openid，我们就进行创建或者查询用户，生成token。然后修改redis里面的isScan的值为true，前端轮训就知道登录了就进行登录跳转。授权的那里其实和jwt一样使用了对称加密，也就是微信进行签名，node服务器去验证。

#### 微信服务器接入为什么要做对称加密呢？

- 保证我们服务的安全，除了微信服务器，其他方式调用我们接口都是不允许的

![](/Users/mohaixiao/Library/Application%20Support/marktext/images/2023-08-31-12-23-48-image.png)

### 你说你用了jwt ，那为什么不用cookie呢，JWT与Cookie的区别和各自适合的场景

对于身份验证和授权机制，JWT（JSON Web Token）和Cookie是两种常见的实现方式。它们有一些区别，并且适用于不同的场景。

1. 数据存储位置：Cookie将身份验证信息存储在浏览器的Cookie中，而JWT将其存储在客户端的Token中（通常是在请求的头部或请求参数中）。

2. 服务器存储状态：使用Cookie时，服务器需要存储会话信息，以便在每个请求中校验和维护会话状态。而JWT是无状态的，服务器不需要存储任何会话信息，只需验证签名即可。

3. 扩展性：由于JWT本身包含了所有必要的信息，可以轻松地跨多个域和服务进行扩展。而使用Cookie需要在不同域之间进行共享会话信息，可能需要额外的配置和处理。

4. 安全性：JWT通过签名和加密来确保数据的完整性和安全性。Cookie在传输过程中可以被窃听、篡改或伪造，但可以通过标记为HttpOnly和Secure来增加安全性。

适用场景：

- Cookie更适合用于传统的Web应用程序，其中涉及到会话管理、CSRF保护等。当希望利用浏览器自动处理Cookie的能力时（如自动发送Cookie），Cookie是一个不错的选择。
- JWT更适合用于分布式的服务架构，如前后端分离的单页应用（SPA）或跨微服务的身份验证。JWT允许无状态的通信，且不需要服务器存储会话信息。

JWT生成token的对称加密

![](/Users/mohaixiao/Library/Application%20Support/marktext/images/2023-08-12-18-26-10-image.png)

https://www.bilibili.com/video/BV1b14y1J7Yv/?spm_id_from=333.788.recommend_more_video.10&vd_source=037b856144283671f89f562ed7eeb263

#### node cors库的原理

Node.js中的`cors`库（跨域资源共享）是一种用于处理跨域请求的中间件。其原理是通过在HTTP响应头中设置特定的CORS标头来允许或拒绝跨域请求。

以下是`cors`库的工作原理：

1. **检查跨域请求：** 当Node.js应用程序收到HTTP请求时，`cors`中间件会检查请求的来源（Origin）、HTTP方法（例如GET、POST）和其他CORS相关的信息，以确定是否为跨域请求。

2. **设置响应头：** 如果请求是跨域请求且符合CORS策略，`cors`中间件将在HTTP响应头中设置以下CORS标头：
   
   - `Access-Control-Allow-Origin`：指定允许访问资源的域。可以是具体的域名或通配符（例如`*`表示允许任何域）。
   
   - `Access-Control-Allow-Methods`：指定允许的HTTP方法，例如GET、POST、PUT等。
   
   - `Access-Control-Allow-Headers`：指定允许的HTTP头，例如`Content-Type`、`Authorization`等。
   
   - `Access-Control-Allow-Credentials`：如果需要发送Cookie，该标头将被设置为`true`。
   
   - `Access-Control-Expose-Headers`：指定响应中允许暴露的HTTP头。
   
   - `Access-Control-Max-Age`：指定预检请求（OPTIONS请求）的最大缓存时间（以秒为单位），以减少对服务器的重复预检请求。

3. **处理预检请求：** 如果收到的是预检请求（OPTIONS请求），`cors`中间件会检查预检请求中的信息，如请求方法和标头，以确定是否允许该请求。如果允许，它将发送一个带有CORS标头的响应以进行实际请求。

4. **处理实际请求：** 对于实际请求，`cors`中间件会继续检查请求的来源、方法和标头，并设置相应的CORS标头。如果一切符合策略，它将允许请求并将响应返回给客户端。

总的来说，`cors`库通过检查请求和设置响应头来实现跨域资源共享。它使服务器能够在安全的情况下与其他域的客户端进行通信，并允许开发人员细粒度地控制哪些域可以访问其资源。这有助于减少潜在的安全风险，同时保持了跨域通信的便利性。

#### 说一下Redis防盗刷机制

通过redis存储图形验证码和前端填写的进行对比，只有校验成功才可以点击获取验证码。

### 服务端渲染是什么？为什么要服务端污染？有做过优化吗？

### 你说你了解性能优化，你做过哪些性能优化？知乎首页如果很多数据，后台给你返回一万条，你会如何做性能优化？

二三面的话，他可能还会问你后端相关的
你在实习过程中印象最深刻的项目是哪一个，难点是什么，如何解决的
你未来的职业发展方向（因为你前后端都涉猎嘛，但是应聘的只是其中一个岗位，我觉得应该会问你职业方向的

### 说一下CI CD流水线，以及其原理,cicd前端工程化这块，你了解多少？大致链路是什么

#### Docker解决了什么？

Docker 是一种开源的容器化平台，它提供了一种轻量级的容器化技术。容器化是一种虚拟化的方法，通过将应用程序及其所有依赖项（库、运行环境等）打包在一个独立可执行的容器中，实现了应用程序在不同操作系统和环境之间的可移植性。

Docker 容器化技术的主要组成部分如下：

1. Docker 镜像（Docker Image）：Docker 镜像是一个只读的模板，包含了构建容器的文件系统、应用程序、相关依赖和配置等。镜像是容器的基础，可以快速创建和部署容器。

2. 容器（Container）：容器是 Docker 运行时实例化的镜像，是一个独立的、隔离的运行环境。每个容器都运行在独立的命名空间中，拥有自己的文件系统、进程空间和网络设置。容器相互之间隔离，可以同时运行多个互不干扰的应用程序。

Docker 容器化技术解决了以下几个问题：

1. 跨平台和可移植性：通过使用 Docker 容器化技术，应用程序及其依赖项可以被打包到一个可移植的容器中，从而实现应用程序在不同操作系统和环境中的一致运行。

2. 快速部署和复制：Docker 容器可以快速启动和停止，使应用程序的部署过程变得非常高效。同时，通过复制和共享 Docker 镜像，可以轻松地在多个环境中部署相同的应用程序，提高了开发和测试的效率。

3. 资源隔离和安全性：Docker 容器提供了良好的隔离性，每个容器都拥有自己的文件系统、进程空间和网络设置，不会相互干扰。这增强了应用程序的安全性，并且可以更好地管理资源的使用情况。

4. 简化依赖管理：Docker 容器将应用程序及其依赖项打包到一个容器中，避免了应用程序与底层操作系统之间的依赖冲突问题。开发人员可以更轻松地管理和控制应用程序所需的依赖关系。

#### docker多阶段构建，docker镜像迁移，怎么迁移镜像？镜像构建原理？

![](/Users/mohaixiao/Library/Application%20Support/marktext/images/2023-08-31-14-13-56-image.png)

cidi简单来说是指持续集成、持续发布，是⼀套实现软件的构建测试部署的⾃动化流程。

我使用的是gitee go 的流水线，也就是每次我们推上去代码之后就启动流水线，gitee go 就是拉去我们的项目代码，执行内部的Docker的,删除上一次构建的镜像打包，构建，部署就行。

### 反向代理和正向代理区别，负载均衡的几种策略你知道吗？docker解决了什么问题？

https://www.bilibili.com/video/BV1vm4y1z7EB/?spm_id_from=333.337.search-card.all.click&vd_source=037b856144283671f89f562ed7eeb263

### Redux

大概说一下Redux的作用，为什么要用Redux。

react 数据流是怎样的，为什么要用 redux？

你刚解释用 redux 的理由，那能不能用 context 上下文，为什么不用，redux的核心原理是什么？在什么场景才会用到？有其他类似的方案了解吗？

### 我看你做了个换肤功能，你能讲讲如何做的吗？换肤是怎么做的？有没有更好的方案

### 说一下CDN查找，cdn链接的步骤是什么，一个数据是怎么访问cdn的

> `CDN`的原理是尽可能的在各个地方分布机房缓存数据，这样即使我们的根服务器远在国外，在国内的用户也可以通过国内的机房迅速加载资源。

> 因此，我们可以将静态资源尽量使用 `CDN` 加载，由于浏览器对于单个域名有并发请求上限，可以考虑使用多个 `CDN` 域名。并且对于 `CDN` 加载静态资源需要注意 `CDN` 域名要与主站不同，否则每次请求都会带上主站的 `Cookie`，平白消耗流量

[CDN工作原理及其在淘宝图片业务中的应用 - 掘金](https://juejin.cn/post/6901479190244098062?searchId=202308222059090FD4918C75279B91A346)

![](/Users/mohaixiao/Library/Application%20Support/marktext/images/2023-08-31-13-49-21-image.png)

### 项目里的登录功能是怎么实现的？项目里关于权限控制这块怎么做的？有了解哪些权限控制的方式？或者说更优雅地进行权限控制？

后台管理系统管理员权限，根据token拿到之后进行判断。是否有role == “ADMIN”

- 登录权限校验
  
  ```js
  // 管理员权限校验
  const checkIsAdmin = (req, res, next) => {
   // 判断有没有登录
   if (req.headers.authorization) {
     let token = req.headers.authorization.split(' ').pop()
     let userInfo = SecretTool.jwtVerify(token)
     // 登录了判断相关权限是否正确
     if (userInfo && userInfo.role === 'ADMIN') {
       next()
       return
    }
  
     res.send(BackCode.buildError(CodeEnum.ADMIN_NOT_ROLE))
  } else {
     res.send(BackCode.buildError(CodeEnum.ACCOUNT_UNLOGIN))
  }
  }
  ```
