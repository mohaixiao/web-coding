### 从输入URL到页面展示，这中间发生了什么？包括之前说的缓存的情况

[从输入URL开始建立前端知识体系 - 掘金](https://juejin.cn/post/6935232082482298911#heading-32)

**基础版本**

- 浏览器根据请求的`URL`交给`DNS`域名解析，找到真实`IP`，向服务器发起请求；
- 服务器交给后台处理完成后返回数据，浏览器接收文件（`HTML、JS、CSS`、图象等）；
- 浏览器对加载到的资源（`HTML、JS、CSS`等）进行语法解析，建立相应的内部数据结构（如`HTML`的`DOM`）；
- 载入解析到的资源文件，渲染页面，完成。

**详细版**

1. 在浏览器地址栏输入URL
2. 浏览器查看**缓存**，如果请求资源在缓存中并且新鲜，跳转到转码步骤
   1. 如果资源未缓存，发起新请求
   2. 如果已缓存，检验是否足够新鲜，足够新鲜直接提供给客户端，否则与服务器进行验证。
   3. 检验新鲜通常有两个HTTP头进行控制`Expires`和`Cache-Control`：
      - HTTP1.0提供Expires，值为一个绝对时间表示缓存新鲜日期
      - HTTP1.1增加了Cache-Control: max-age=,值为以秒为单位的最大新鲜时间
3. 浏览器**解析URL**获取协议，主机，端口，path
4. 浏览器**组装一个HTTP（GET）请求报文**
5. 浏览器**获取主机ip地址**，过程如下：
   1. 浏览器缓存
   2. 本机缓存
   3. hosts文件
   4. 路由器缓存
   5. ISP DNS缓存
   6. DNS递归查询（可能存在负载均衡导致每次IP不一样）
6. **打开一个socket与目标IP地址，端口建立TCP链接**，三次握手如下：
   1. 客户端发送一个TCP的**SYN=1，Seq=X**的包到服务器端口
   2. 服务器发回**SYN=1， ACK=X+1， Seq=Y**的响应包
   3. 客户端发送**ACK=Y+1， Seq=Z**
7. TCP链接建立后**发送HTTP请求**
8. 服务器接受请求并解析，将请求转发到服务程序，如虚拟主机使用HTTP Host头部判断请求的服务程序
9. 服务器检查**HTTP请求头是否包含缓存验证信息**如果验证缓存新鲜，返回**304**等对应状态码
10. 处理程序读取完整请求并准备HTTP响应，可能需要查询数据库等操作
11. 服务器将**响应报文通过TCP连接发送回浏览器**
12. 浏览器接收HTTP响应，然后根据情况选择**关闭TCP连接或者保留重用，关闭TCP连接的四次挥手如下**：
    1. 主动方发送**Fin=1， Ack=Z， Seq= X**报文
    2. 被动方发送**ACK=X+1， Seq=Z**报文
    3. 被动方发送**Fin=1， ACK=X， Seq=Y**报文
    4. 主动方发送**ACK=Y， Seq=X**报文
13. 浏览器检查响应状态吗：是否为1XX，3XX， 4XX， 5XX，这些情况处理与2XX不同
14. 如果资源可缓存，**进行缓存**
15. 对响应进行**解码**（例如gzip压缩）
16. 根据资源类型决定如何处理（假设资源为HTML文档）
17. **解析HTML文档，构件DOM树，下载资源，构造CSSOM树，执行js脚本**，这些操作没有严格的先后顺序，以下分别解释
18. **构建DOM树**：
    1. **Tokenizing**：根据HTML规范将字符流解析为标记
    2. **Lexing**：词法分析将标记转换为对象并定义属性和规则
    3. **DOM construction**：根据HTML标记关系将对象组成DOM树
19. 解析过程中遇到图片、样式表、js文件，**启动下载**
20. 构建**CSSOM树**：
    1. **Tokenizing**：字符流转换为标记流
    2. **Node**：根据标记创建节点
    3. **CSSOM**：节点创建CSSOM树
21. **[根据DOM树和CSSOM树构建渲染树 (opens new window)](https://developers.google.com/web/fundamentals/performance/critical-rendering-path/render-tree-construction)**:
    1. 从DOM树的根节点遍历所有**可见节点**，不可见节点包括：1）`script`,`meta`这样本身不可见的标签。2)被css隐藏的节点，如`display: none`
    2. 对每一个可见节点，找到恰当的CSSOM规则并应用
    3. 发布可视节点的内容和计算样式
22. **js解析如下**：
    1. 浏览器创建Document对象并解析HTML，将解析到的元素和文本节点添加到文档中，此时**document.readystate为loading**
    2. HTML解析器遇到**没有async和defer的script时**，将他们添加到文档中，然后执行行内或外部脚本。这些脚本会同步执行，并且在脚本下载和执行时解析器会暂停。这样就可以用document.write()把文本插入到输入流中。**同步脚本经常简单定义函数和注册事件处理程序，他们可以遍历和操作script和他们之前的文档内容**
    3. 当解析器遇到设置了**async**属性的script时，开始下载脚本并继续解析文档。脚本会在它**下载完成后尽快执行**，但是**解析器不会停下来等它下载**。异步脚本**禁止使用document.write()**，它们可以访问自己script和之前的文档元素
    4. 当文档完成解析，document.readState变成interactive
    5. 所有**defer**脚本会**按照在文档出现的顺序执行**，延迟脚本**能访问完整文档树**，禁止使用document.write()
    6. 浏览器**在Document对象上触发DOMContentLoaded事件**
    7. 此时文档完全解析完成，浏览器可能还在等待如图片等内容加载，等这些**内容完成载入并且所有异步脚本完成载入和执行**，document.readState变为complete，window触发load事件
23. **显示页面**（HTML解析过程中会逐步显示页面）

**详细简版**

1. 从浏览器接收`url`到开启网络请求线程（这一部分可以展开浏览器的机制以及进程与线程之间的关系）

2. 开启网络线程到发出一个完整的`HTTP`请求（这一部分涉及到dns查询，`TCP/IP`请求，五层因特网协议栈等知识）

3. 从服务器接收到请求到对应后台接收到请求（这一部分可能涉及到负载均衡，安全拦截以及后台内部的处理等等）

4. 后台和前台的`HTTP`交互（这一部分包括`HTTP`头部、响应码、报文结构、`cookie`等知识，可以提下静态资源的`cookie`优化，以及编码解码，如`gzip`压缩等）

5. 单独拎出来的缓存问题，`HTTP`的缓存（这部分包括http缓存头部，`ETag`，`catch-control`等）

6. 浏览器接收到`HTTP`数据包后的解析流程（解析`html`-词法分析然后解析成`dom`树、解析`css`生成`css`规则树、合并成`render`树，然后`layout`、`painting`渲染、复合图层的合成、`GPU`绘制、外链资源的处理、`loaded`和`DOMContentLoaded`等）

7. `CSS`的可视化格式模型（元素的渲染规则，如包含块，控制框，`BFC`，`IFC`等概念）

8. `JS`引擎解析过程（`JS`的解释阶段，预处理阶段，执行阶段生成执行上下文，`VO`，作用域链、回收机制等等）

9. 其它（可以拓展不同的知识模块，如跨域，web安全，`hybrid`模式等等内容）

### js文件如何阻塞渲染 怎么解决？

JavaScript 会阻塞 DOM 生成

> `JavaScript` 会阻塞 `DOM`生成，而样式文件又会阻塞 `JavaScript` 的执行，所以在实际的工程中需要重点关注 `JavaScript` 文件和样式表文件，使用不当会影响到页面性能的

> 当渲染进程接收 HTML 文件字节流时，会先开启一个预解析线程，如果遇到 JavaScript 文件或者 CSS 文件，那么预解析线程会提前下载这些数据

- 如果代码里引用了外部的 CSS 文件，那么在执行 JavaScript 之前，还需要等待外部的 CSS 文件下载完成，并解析生成 CSSOM 对象之后，才能执行 JavaScript 脚本。
- 而 JavaScript 引擎在解析 JavaScript 之前，是不知道 JavaScript 是否操纵了 CSSOM 的，所以渲染引擎在遇到 JavaScript 脚本时，不管该脚本是否操纵了 CSSOM，都会执行 CSS 文件下载，解析操作，再执行 JavaScript 脚本。
- 不管 CSS 文件和 JavaScript 文件谁先到达，都要先等到 CSS 文件下载完成并生成 CSSOM，然后再执行 JavaScript 脚本，最后再继续构建 DOM，构建布局树，绘制页面

css 加载会造成阻塞吗 ？

- `DOM` 和 `CSSOM` 通常是并行构建的,所以 CSS 加载不会阻塞 DOM 的解析。
- 然而,由于 `Render Tree` 是依赖于 DOM Tree 和 `CSSOM Tree` 的,
- 所以他必须等待到 `CSSOM Tree` 构建完成,也就是 CSS 资源加载完成(或者 CSS 资源加载失败)后,才能开始渲染。
- 因此,CSS 加载会阻塞 Dom 的渲染。
- 由于 JavaScript 是可操纵 DOM 和 css 样式的,如果在修改这些元素属性同时渲染界面（即 JavaScript 线程和 UI线程同时运行）,那么渲染线程前后获得的元素数据就可能不一致了。
- 因此为了防止渲染出现不可预期的结果,浏览器设置 GUI 渲染线程与 JavaScript 引擎为互斥的关系。因此,样式表会在后面的 js 执行前先加载执行完毕,所以css 会阻塞后面 js 的执行

为什么 JS 阻塞页面加载 ?

- 由于 JavaScript 是可操纵 DOM 的,如果在修改这些元素属性同时渲染界面（即 JavaScript 线程和 UI 线程同时运行）,那么渲染线程前后获得的元素数据就可能不一致了
- 因此为了防止渲染出现不可预期的结果,浏览器设置 GUI 渲染线程与 JavaScript 引擎为互斥的关系。
- 由于 GUI 渲染线程与 JavaScript 执行线程是互斥的关系,当浏览器在执行 JavaScript 程序的时候,GUI 渲染线程会被保存在一个队列中,直到 JS 程序执行完成,才会接着执行
- 因此如果 JS执行的时间过长,这样就会造成页面的渲染不连贯,导致页面渲染加载阻塞的感觉

什么情况阻塞渲染

- 首先渲染的前提是生成渲染树，所以 `HTML` 和 `CSS` 肯定会阻塞渲染。如果你想渲染的越快，你越应该降低一开始需要渲染的文件大小，并且扁平层级，优化选择器。
- 然后当浏览器在解析到 `script` 标签时，会暂停构建 `DOM`，完成后才会从暂停的地方重新开始。也就是说，如果你想首屏渲染的越快，就越不应该在首屏就加载 `JS`文件，这也是都建议将 `script` 标签放在 `body` 标签底部的原因。
- 当然在当下，并不是说 `script` 标签必须放在底部，因为你可以给 `script` 标签添加 `defer` 或者 `async` 属性。
- 当 `script` 标签加上 `defer` 属性以后，表示该 `JS` 文件会并行下载，但是会放到 `HTML` 解析完成后顺序执行，所以对于这种情况你可以把 `script`标签放在任意位置。
- 对于没有任何依赖的 `JS` 文件可以加上 `async` 属性，表示 `JS` 文件下载和解析不会阻塞渲染。

### 告别阻塞：CSS 与 JS 的加载顺序优化

HTML、CSS 和 JS，都具有**阻塞渲染**的特性。

HTML 阻塞

        天经地义——没有 HTML，何来 DOM？没有 DOM，渲染和优化，都是空谈。

CSS 的阻塞

- 在刚刚的过程中，我们提到 DOM 和 CSSOM 合力才能构建渲染树。这一点会给性能造成严重影响：默认情况下，CSS 是阻塞的资源。浏览器在构建 CSSOM 的过程中，**不会渲染任何已处理的内容**。即便 DOM 已经解析完毕了，只要 CSSOM 不 OK，那么渲染这个事情就不 OK（这主要是为了避免没有 CSS 的 HTML 页面丑陋地“裸奔”在用户眼前）。
- 我们知道，只有当我们开始解析 HTML 后、解析到 link 标签或者 style 标签时，CSS 才登场，CSSOM 的构建才开始。很多时候，DOM 不得不等待 CSSOM。因此我们可以这样总结：

> CSS 是阻塞渲染的资源。需要将它尽早、尽快地下载到客户端，以便缩短首次渲染的时间。

尽早（将 CSS 放在 head 标签里）和尽快（启用 CDN 实现静态资源加载速度的优化）。这个“把 CSS 往前放”的动作，已经内化为一种编码习惯。这个“习惯”不是空穴来风，它是由 CSS 的特性决定的。

JS 的阻塞

- 在首次渲染过程中，JS 并不是一个非登场不可的角色——没有 JS，CSSOM 和 DOM 照样可以组成渲染树，页面依然会呈现——即使它死气沉沉、毫无交互。
- JS 的作用在于**修改**，它帮助我们修改网页的方方面面：内容、样式以及它如何响应用户交互。这“方方面面”的修改，本质上都是对 DOM 和 CSSDOM 进行修改。因此 JS 的执行会阻止 CSSOM，在我们不作显式声明的情况下，它也会阻塞 DOM。

我们通过一个🌰来理解一下这个机制：

```
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>JS阻塞测试</title>
  <style>
    #container {
      background-color: yellow;
      width: 100px;
      height: 100px;
    }
  </style>
  <script>
    // 尝试获取container元素
    var container = document.getElementById("container")
    console.log('container', container)
  </script>
</head>
<body>
  <div id="container"></div>
  <script>
    // 尝试获取container元素
    var container = document.getElementById("container")
    console.log('container', container)
    // 输出container元素此刻的背景色
 console.log('container bgColor', getComputedStyle(container).backgroundColor)
  </script>
  <style>
    #container {
      background-color: blue;
    }
  </style>
</body>
</html>
```

三个 console 的结果分别为：

![](https://s.poetries.work/gitee/2020/07/performance/36.png)

- 注：本例仅使用了内联 JS 做测试。把这部分 JS 当做外部文件引入看看效果——它们的表现一致。
- 第一次尝试获取 id 为 container 的 DOM 失败，这说明 JS 执行时阻塞了 DOM，后续的 DOM 无法构建；第二次才成功，这说明脚本块只能找到在它前面构建好的元素。这两者结合起来，“阻塞 DOM”得到了验证。再看第三个 console，尝试获取 CSS 样式，获取到的是在 JS 代码执行前的背景色（yellow），而非后续设定的新样式（blue），说明 CSSOM 也被阻塞了。
- **JS 引擎是独立于渲染引擎存在的**。我们的 JS 代码在文档的何处插入，就在何处执行。当 HTML 解析器遇到一个 script 标签时，它会暂停渲染过程，将控制权交给 JS 引擎。JS 引擎对内联的 JS 代码会直接执行，对外部 JS 文件还要先获取到脚本、再进行执行。等 JS 引擎运行完毕，浏览器又会把控制权还给渲染引擎，继续 CSSOM 和 DOM 的构建。 因此与其说是 JS 把 CSS 和 HTML 阻塞了，不如说是 JS 引擎抢走了渲染引擎的控制权。
- 理解了阻塞的表现与原理，思考一个问题。浏览器之所以让 JS 阻塞其它的活动，是因为它不知道 JS 会做什么改变，担心如果不阻止后续的操作，会造成混乱。但是我们是写 JS 的人，我们知道 JS 会做什么改变。假如我们可以确认一个 JS 文件的执行时机并不一定非要是此时此刻，我们就可以通过对它使用 defer 和 async 来避免不必要的阻塞，这里我们就引出了外部 JS 的三种加载方式。

**3. JS的三种加载方式**

- 正常模式：

```
<script src="index.js"></script>
```

> 这种情况下 JS 会阻塞浏览器，浏览器必须等待 `index.js` 加载和执行完毕才能去做其它事情。

- async 模式：

```
<script async src="index.js"></script>
```

> `async` 模式下，JS 不会阻塞浏览器做任何其它的事情。它的加载是异步的，当它加载结束，JS 脚本会**立即执行**。

- defer 模式：

```
<script defer src="index.js"></script>
```

> `defer` 模式下，JS 的加载是异步的，执行是**被推迟的**。等整个文档解析完成、`DOMContentLoaded` 事件即将被触发时，被标记了 `defer` 的 JS 文件才会开始依次执行。

- 从应用的角度来说，一般当我们的脚本与 DOM 元素和其它脚本之间的依赖关系不强时，我们会选用 `async`；当脚本依赖于 DOM 元素和其它脚本的执行结果时，我们会选用 `defer`。
- 通过审时度势地向 `script` 标签添加 `async/defer`，我们就可以告诉浏览器在等待脚本可用期间不阻止其它的工作，这样可以显著提升性能。

小结

- 我们知道，当 `JS` 登场时，往往意味着对 `DOM` 的操作。DOM 操作所导致的性能开销的“昂贵”，雅虎军规里很重要的一条就是“尽量减少 DOM 访问”。

### HTTP的几种请求方法用途

- `GET`方法
  
  - 发送一个请求来取得服务器上的某一资源

- `POST`方法
  
  - 向`URL`指定的资源提交数据或附加新的数据

- `PUT`方法
  
  - 跟`POST`方法很像，也是想服务器提交数据。但是，它们之间有不同。`PUT`指定了资源在服务器上的位置，而`POST`没有

- `HEAD`方法
  
  - 只请求页面的首部

- `DELETE`方法
  
  - 删除服务器上的某资源

- `OPTIONS`方法
  
  - 它用于获取当前`URL`所支持的方法。如果请求成功，会有一个`Allow`的头包含类似`“GET,POST”`这样的信息

- `TRACE`方法
  
  - `TRACE`方法被用于激发一个远程的，应用层的请求消息回路

- `CONNECT`方法
  
  - 把请求连接转换到透明的`TCP/IP`通道

### HTTP缓存，浏览器缓存（强制缓存 协商缓存）如何实现 强缓存 和 协商缓存？那些协议属性会触发缓存？缓存存在浏览器的哪个地方

- **关于缓存介绍**
  
  - 为什么需要缓存？减少网络请求（网络请求不稳定性），让页面渲染更快
  - 哪些资源可以被缓存？静态资源（`js` `css` `img`）`webpack`打包加`contenthash`根据内容生成`hash`

- **http缓存策略**（强制缓存 + 协商缓存）都存在浏览器的内存和硬盘内。
  
  - **强制缓存**
    - 服务端在`Response Headers`中返回给客户端
    - `Cache-Control`：`max-age=31536000`（单位：秒）一年
    - `Cache-Control`的值
      - `max-age`（常用）缓存的内容将在`max-age`秒后失效
      - `no-cache`（常用）不要本地强制缓存，正常向服务端请求（只要服务端最新的内容）。需要使用协商缓存来验证缓存数据（`Etag` `Last-Modified`）
      - `no-store` 不要本地强制缓存，也不要服务端做缓存，所有内容都不会缓存，强制缓存和协商缓存都不会触发
      - `public` 所有内容都将被缓存（客户端和代理服务器都可缓存）
      - `private` 所有内容只有客户端可以缓存
    - **Expires**
      - `Expires`：`Thu, 31 Dec 2037 23:55:55 GMT`（过期时间）
      - 已被`Cache-Control`代替
    - **Expires和Cache-Control的区别**
      - `Expires`是`HTTP1.0`的产物，`Cache-Control`是`HTTP1.1`的产物
      - `Expires`是服务器返回的具体过期时间，`Cache-Control`是相对时间
      - `Expires`存在兼容性问题，`Cache-Control`优先级更高
    - **强制缓存的优先级高于协商缓存**
    - **强制缓存的流程**
      - 浏览器第一次请求资源，服务器返回资源和`Cache-Control` `Expires`
      - 浏览器第二次请求资源，会带上`Cache-Control` `Expires`，服务器根据这两个值判断是否命中强制缓存
      - 命中强制缓存，直接从缓存中读取资源，返回给浏览器
      - 未命中强制缓存，会带上`If-Modified-Since` `If-None-Match`，服务器根据这两个值判断是否命中协商缓存
      - 命中协商缓存，返回`304`，浏览器直接从缓存中读取资源
      - 未命中协商缓存，返回`200`，浏览器重新请求资源
    - **强制缓存的流程图** ![](https://s.poetries.work/uploads/2023/02/cf357b148b63c080.png) ![](https://s.poetries.work/uploads/2023/02/c64e9237d005100c.png)
  - **协商缓存**
    - 服务端缓存策略
    - 服务端判断客户端资源，是否和服务端资源一样
    - 如果判断一致则返回`304`（不在返回`js`、图片内容等资源），否则返回`200`和最新资源
    - **服务端怎么判断客户端资源一样？** 根据资源标识
      - 在`Response Headers`中，有两种
      - `Last-Modified`和`Etag`会优先使用`Etag`，`Last-Modified`只能精确到秒级，如果资源被重复生成而内容不变，则`Etag`更准确
      - `Last-Modified` 服务端返回的资源的最后修改时间
        - `If-Modified-Since` 客户端请求时，携带的资源的最后修改时间（即`Last-Modified`的值） ![](https://s.poetries.work/uploads/2023/02/282933521c137ef6.png)
      - `Etag`服务端返回的资源的唯一标识（一个字符串，类似指纹）
        - `If-None-Matche` 客户端请求时，携带的资源的唯一标识（即`Etag`的值） ![](https://s.poetries.work/uploads/2023/02/5410537fc2ebf124.png)
      - **Headers示例** ![](https://s.poetries.work/uploads/2023/02/704949dd8a110763.png)
      - **请求示例** 通过`Etag`或`Last-Modified`命中缓存，没有返回资源，返回`304`，体积非常小 ![](https://s.poetries.work/uploads/2023/02/8aa4cc91818455d9.png)
  - **HTTP缓存总结** ![](https://s.poetries.work/uploads/2023/02/e808802f780e55c9.png)

- **刷新操作方式，对缓存的影响**
  
  - 正常操作：地址栏输入`url`，跳转链接，前进后退
  - 手动操作：`F5`，点击刷新，右键菜单刷新
  - 强制刷新：`ctrl + F5` 或 `command + r`

- **不同刷新操作，不同缓存策略**
  
  - 正常操作：强缓存有效，协商缓存有效
  - 手动操作：强缓存失效，协商缓存有效
  - 强制刷新：强缓存失效，协商缓存失效
  
  ![](C:\Users\mohaixiao\AppData\Roaming\marktext\images\2023-04-09-18-19-50-image.png)

- **小结**
  
  - 强缓存`Cache-Contorl`、`Expired`（弃用）
  - 协商缓存`Last-Modified`/`If-Modified-Since`和`Etag`/`If-None-Matche`，`304`状态码

### 本地存储——从 Cookie 到 Web Storage、IndexDB

**Cookie** 

- `Cookie` 的本职工作并非本地存储，而是“维持状态”。
- 状态管理的问题：HTTP 协议是一个无状态协议，服务器接收客户端的请求，返回一个响应，服务器并没有记录下关于客户端的任何信息。那么下次请求的时候，如何让服务器知道“我是我”呢？
- `Cookie` 就是一个存储在浏览器里的一个小小的文本文件，它附着在 `HTTP` 请求上，在浏览器和服务器之间“飞来飞去”。它可以携带用户信息，当服务器检查 Cookie 的时候，便可以获取到客户端的状态。

关于 Cookie 的详细内容，在 Chrome 的 Application 面板中查看到：

![](https://s.poetries.work/gitee/2020/07/performance/21.png)

**Cookie 以键值对的形式存在**。

Cookie的性能劣势

**1. Cookie 不够大**

> Cookie是有体积上限的，它最大只能有 `4KB`。当 `Cookie` 超过 `4KB` 时，它将面临被裁切的命运。这样看来，Cookie只能用来存取少量的信息。

**2. 过量的 Cookie 会带来巨大的性能浪费**

**Cookie 是紧跟域名的**。我们通过响应头里的 `Set-Cookie` 指定要存储的 `Cookie` 值。默认情况下，`domain` 被设置为设置 `Cookie` 页面的主机名，我们也可以手动设置 `domain` 的值：

```
Set-Cookie: name=xiuyan; domain=xiuyan.me
```

**同一个域名下的所有请求，都会携带 Cookie**。如果我们此刻仅仅是请求一张图片或者一个 CSS 文件，我们也要携带一个 Cookie 跑来跑去（关键是 Cookie 里存储的信息我现在并不需要）。Cookie 虽然小，请求却可以有很多，随着请求的叠加，不必要的 Cookie 带来的开销将是无法想象的。

`Cookie` 也渐渐演化为了一个“存储多面手”——它不仅仅被用于维持状态，还被塞入了一些乱七八糟的其它信息，被迫承担起了本地存储的“重任”。在没有更好的本地存储解决方案的年代里，`Cookie` 小小的身体里承载了 `4KB` 内存所不能承受的压力。

为了弥补 `Cookie` 的局限性，`Web Storage` 出现了。

**Storage**

> `Web Storage` 是 `HTML5` 专门为浏览器存储而提供的数据存储机制。它又分为 `Local Storage` 与 `Session Storage`。

**1. Local Storage 与 Session Storage 的区别**

两者的区别在于**生命周期**与**作用域**的不同。

- 生命周期：`Local Storage` 是持久化的本地存储，存储在其中的数据是永远不会过期的，使其消失的唯一办法是手动删除；而 `Session Storage` 是临时性的本地存储，它是会话级别的存储，当会话结束（页面被关闭）时，存储内容也随之被释放。
- 作用域：`Local Storage`、`Session Storage` 和 `Cookie` 都遵循同源策略。但 `Session Storage` 特别的一点在于，即便是相同域名下的两个页面，只要它们**不在同一个浏览器窗口中**打开，那么它们的 `Session Storage` 内容便无法共享。

**1. Web Storage 的特性**

- 存储容量大： `Web Storage` 根据浏览器的不同，存储容量可以达到 `5-10M` 之间。
- 仅位于浏览器端，不与服务端发生通信。

**2. Web Storage 核心 API 使用示例**

> `Web Storage` 保存的数据内容和 `Cookie` 一样，是文本内容，以键值对的形式存在。`Local Storage` 与 `Session Storage` 在 `API` 方面无异，这里我们以 `localStorage` 为例：

- 存储数据：`setItem()`

```
localStorage.setItem('user_name', 'xiuyan')
```

- 读取数据： `getItem()`

```
localStorage.getItem('user_name')
```

- 删除某一键名对应的数据： `removeItem()`

```
localStorage.removeItem('user_name')
```

- 清空数据记录：`clear()`

```
localStorage.clear()
```

**应用场景**

**1. Local Storage**

> `Local Storage` 在存储方面没有什么特别的限制，理论上 `Cookie` 无法胜任的、可以用简单的键值对来存取的数据存储任务，都可以交给 `Local Storage` 来做。

这里给大家举个例子，考虑到 `Local Storage` 的特点之一是**持久**，有时我们更倾向于用它来存储一些内容稳定的资源。比如图片内容丰富的电商网站会用它来存储 `Base64` 格式的图片字符串：

![](https://s.poetries.work/gitee/2020/07/performance/22.png)

有的网站还会用它存储一些不经常更新的 CSS、JS 等静态资源。

**2. Session Storage**

> `Session Storage` 更适合用来存储生命周期和它同步的**会话级别**的信息。这些信息只适用于当前会话，当你开启新的会话时，它也需要相应的更新或释放。比如微博的 `Session Storage` 就主要是存储你本次会话的浏览足迹：

![](https://s.poetries.work/gitee/2020/07/performance/23.png)

- `lasturl` 对应的就是你上一次访问的 `URL` 地址，这个地址是即时的。当你切换 `URL` 时，它随之更新，当你关闭页面时，留着它也确实没有什么意义了，干脆释放吧。这样的数据用 `Session Storage` 来处理再合适不过。

那么 `Web Storage` 是否能 hold 住所有的存储场景呢？

> 答案是否定的。`Web Storage` 是一个从定义到使用都非常简单的东西。它使用键值对的形式进行存储，这种模式有点类似于对象，却甚至连对象都不是——它只能存储字符串，要想得到对象，我们还需要先对字符串进行一轮解析。

`Web Storage` 是对 `Cookie` 的拓展，它只能用于存储少量的简单数据。当遇到大规模的、结构复杂的数据时，`Web Storage` 也爱莫能助了。我们就要清楚`IndexDB`！

**终极形态：IndexDB**

> `IndexDB` 是一个**运行在浏览器上的非关系型数据库**。既然是数据库了，那就不是 `5M`、`10M` 这样小打小闹级别了。理论上来说，`IndexDB` 是没有存储上限的（一般来说不会小于 `250M`）。它不仅可以存储字符串，还可以存储二进制数据。

我们遵循 MDN 推荐的操作模式，通过一个基本的 IndexDB 使用流程，旨在对 `IndexDB` 形成一个感性的认知：

1. 打开/创建一个 `IndexDB` 数据库（当该数据库不存在时，`open` 方法会直接创建一个名为 xiaoceDB 新数据库）。

```
  // 后面的回调中，我们可以通过event.target.result拿到数据库实例
  let db
  // 参数1位数据库名，参数2为版本号
  const request = window.indexedDB.open("xiaoceDB", 1)
  // 使用IndexDB失败时的监听函数
  request.onerror = function(event) {
     console.log('无法使用IndexDB')
   }
  // 成功
  request.onsuccess  = function(event){
    // 此处就可以获取到db实例
    db = event.target.result
    console.log("你打开了IndexDB")
  }
```

2. 创建一个 `object store`（object store 对标到数据库中的“表”单位）。

```
// onupgradeneeded事件会在初始化数据库/版本发生更新时被调用，
//我们在它的监听函数中创建object store
request.onupgradeneeded = function(event){
  let objectStore
  // 如果同名表未被创建过，则新建test表
  if (!db.objectStoreNames.contains('test')) {
    objectStore = db.createObjectStore('test', { keyPath: 'id' })
  }
}  
```

3. 构建一个事务来执行一些数据库操作，像增加或提取数据等。

```
  // 创建事务，指定表格名称和读写权限
  const transaction = db.transaction(["test"],"readwrite")
  // 拿到Object Store对象
  const objectStore = transaction.objectStore("test")
  // 向表格写入数据
  objectStore.add({id: 1, name: 'xiuyan'})
```

4. 通过监听正确类型的事件以等待操作完成。

```
  // 操作成功时的监听函数
  transaction.oncomplete = function(event) {
    console.log("操作成功")
  }
  // 操作失败时的监听函数
  transaction.onerror = function(event) {
    console.log("这里有一个Error")
  }
```

**IndexDB 的应用场景**

在 `IndexDB` 中，我们可以创建多个数据库，一个数据库中创建多张表，一张表中存储多条数据——这足以 `hold` 住复杂的结构性数据。`IndexDB` 可以看做是 `LocalStorage` 的一个升级，当数据的复杂度和规模上升到了 `LocalStorage` 无法解决的程度，可以请出 `IndexDB` 

### 刷新后还能访问sessionstorage原数据吗?

是的，刷新页面后仍然可以访问sessionStorage中存储的原始数据。sessionStorage中存储的数据只有在关闭浏览器标签页或清除缓存时才会被销毁。因此，即使刷新页面，sessionStorage中存储的数据仍然存在，并且可以通过JavaScript代码进行访问和操作。

### sessionStorage localStorage cookie 如果存满了怎么办,如果 localStorage 存满了，再往里存东西，或者要存的东西超过了剩余容量，会发生什么？

如果 sessionStorage、localStorage 或 cookie 存满了，新的数据无法存储。解决方法可以是删除旧数据或使用其他存储方式。例如，使用服务器端存储或IndexedDB（浏览器中的另一种本地存储机制）。再存的话会存不进去并报错（QuotaExceededError）

[localStorage 存满了怎么办？ | 全栈 | 汪苗的个人网站-全栈修炼 —— Wang Miao&#x27;s Personal Website](http://wangmiaozero.cn/701)

### HTTP 与 HTTPS 有哪些区别？

- HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷， TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。

- HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。

- 两者的默认端口不一样，HTTP 默认端口号是 80，HTTPS 默认端口号是 443。

- HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。

### 垃圾回收：垃圾数据如何自动回收，垃圾回收机制的执行时机，会不会阻塞线程？

有些数据被使用之后，可能就不再需要了，我们把这种数据称为垃圾数据。如果这些垃圾数据一直保存在内存中，那么内存会越用越多，所以我们需要对这些垃圾数据进行回收，以释放有限的内存空间

**不同语言的垃圾回收策略**

通常情况下，垃圾数据回收分为手动回收和自动回收两种策略。

如 C/C++ 就是使用手动回收策略，何时分配内存、何时销毁内存都是由代码控制的，你可以参考下面这段 C 代码：

```
// 在堆中分配内存
char* p =  (char*)malloc(2048);  
// 在堆空间中分配 2048 字节的空间，并将分配后的引用地址保存到 p 中

 // 使用 p 指向的内存
 {
   //....
 }

// 使用结束后，销毁这段内存
free(p)；
p = NULL；
```

从上面这段 C 代码可以看出来，要使用堆中的一块空间，我们需要先调用 mallco 函数分配内存，然后再使用；当不再需要这块数据的时候，就要手动调用 free 函数来释放内存。如果这段数据已经不再需要了，但是又没有主动调用 free 函数来销毁，那么这种情况就被称为内存泄漏。

另外一种使用的是自动垃圾回收的策略，如 JavaScript、Java、Python 等语言，产生的垃圾数据是由垃圾回收器来释放的，并不需要手动通过代码来释放。

对于 JavaScript 而言，也正是这个“自动”释放资源的特性带来了很多困惑，也让一些 JavaScript 开发者误以为可以不关心内存管理，这是一个很大的误解。

因为数据是存储在栈和堆两种内存空间中的，所以接下来我们就来分别介绍“栈中的垃圾数据”和“堆中的垃圾数据”是如何回收的。

**调用栈中的数据是如何回收的**

首先是调用栈中的数据，我们还是通过一段示例代码的执行流程来分析其回收机制，具体如下：

```
function foo(){
    var a = 1
    var b = {name:" 极客邦 "}
    function showName(){
      var c = " 极客时间 "
      var d = {name:" 极客时间 "}
    }
    showName()
}
foo()
```

当执行到第 6 行代码时，其调用栈和堆空间状态图如下所示：

![](https://s.poetries.work/gitee/2019/11/10.png)

从图中可以看出，原始类型的数据被分配到栈中，引用类型的数据会被分配到堆中。当 foo 函数执行结束之后，foo 函数的执行上下文会从堆中被销毁掉，那么它是怎么被销毁的呢？下面我们就来分析一下。

在上篇文章中，我们简单介绍过了，如果执行到 showName 函数时，那么 JavaScript 引擎会创建 showName 函数的执行上下文，并将 showName 函数的执行上下文压入到调用栈中，最终执行到 showName 函数时，其调用栈就如上图所示。与此同时，还有一个记录当前执行状态的指针（称为 ESP），指向调用栈中 showName 函数的执行上下文，表示当前正在执行 showName 函数。

接着，当 showName 函数执行完成之后，函数执行流程就进入了 foo 函数，那这时就需要销毁 showName 函数的执行上下文了。ESP 这时候就帮上忙了，JavaScript 会将 ESP 下移到 foo 函数的执行上下文，这个下移操作就是销毁 showName 函数执行上下文的过程。

你可能会有点懵，ESP 指针向下移动怎么就能把 showName 的执行上下文销毁了呢？具体你可以看下面这张移动 ESP 前后的对比图

![](https://s.poetries.work/gitee/2019/11/11.png)

从图中可以看出，当 showName 函数执行结束之后，ESP 向下移动到 foo 函数的执行上下文中，上面 showName 的执行上下文虽然保存在栈内存中，但是已经是无效内存了。比如当 foo 函数再次调用另外一个函数时，这块内容会被直接覆盖掉，用来存放另外一个函数的执行上下文。

所以说，当一个函数执行结束之后，JavaScript 引擎会通过向下移动 ESP 来销毁该函数保存在栈中的执行上下文。

**堆中的数据是如何回收的**

通过上面的讲解，我想现在你应该已经知道，当上面那段代码的 foo 函数执行结束之后，ESP 应该是指向全局执行上下文的，那这样的话，showName 函数和 foo 函数的执行上下文就处于无效状态了，不过保存在堆中的两个对象依然占用着空间，如下图所示

![](https://s.poetries.work/gitee/2019/11/12.png)

从图中可以看出，1003 和 1050 这两块内存依然被占用。要回收堆中的垃圾数据，就需要用到 JavaScript 中的垃圾回收器了。

 Chrome 的 JavaScript 引擎 V8 来分析下堆中的垃圾数据是如何回收的。

**代际假说和分代收集**

不过在正式介绍 V8 是如何实现回收之前，你需要先学习下代际假说（The Generational Hypothesis）的内容，这是垃圾回收领域中一个重要的术语，后续垃圾回收的策略都是建立在该假说的基础之上的，所以很是重要。

**代际假说有以下两个特点：**

- 第一个是大部分对象在内存中存在的时间很短，简单来说，就是很多对象一经分配内存，很快就变得不可访问；
- 第二个是不死的对象，会活得更久。

其实这两个特点不仅仅适用于 JavaScript，同样适用于大多数的动态语言，如 Java、Python 等。

通常，垃圾回收算法有很多种，但是并没有哪一种能胜任所有的场景，你需要权衡各种场景，根据对象的生存周期的不同而使用不同的算法，以便达到最好的效果。

所以，在 V8 中会把堆分为新生代和老生代两个区域，新生代中存放的是生存时间短的对象，老生代中存放的生存时间久的对象。

新生区通常只支持 1～8M 的容量，而老生区支持的容量就大很多了。对于这两块区域，V8 分别使用两个不同的垃圾回收器，以便更高效地实施垃圾回收。

- 副垃圾回收器，主要负责新生代的垃圾回收。

- 主垃圾回收器，主要负责老生代的垃圾回收。
  
  **垃圾回收器的工作流程**

现在你知道了 V8 把堆分成两个区域——新生代和老生代，并分别使用两个不同的垃圾回收器。其实不论什么类型的垃圾回收器，它们都有一套共同的执行流程。

第一步是标记空间中活动对象和非活动对象。所谓活动对象就是还在使用的对象，非活动对象就是可以进行垃圾回收的对象。

第二步是回收非活动对象所占据的内存。其实就是在所有的标记完成之后，统一清理内存中所有被标记为可回收的对象。

第三步是做内存整理。一般来说，频繁回收对象后，内存中就会存在大量不连续空间，我们把这些不连续的内存空间称为内存碎片。当内存中出现了大量的内存碎片之后，如果需要分配较大连续内存的时候，就有可能出现内存不足的情况。所以最后一步需要整理这些内存碎片，但这步其实是可选的，因为有的垃圾回收器不会产生内存碎片，比如接下来我们要介绍的副垃圾回收器。

**副垃圾回收器**

副垃圾回收器主要负责新生区的垃圾回收。而通常情况下，大多数小的对象都会被分配到新生区，所以说这个区域虽然不大，但是垃圾回收还是比较频繁的。

新生代中用Scavenge 算法来处理。所谓 Scavenge 算法，是把新生代空间对半划分为两个区域，一半是对象区域，一半是空闲区域，如下图所示

![](https://s.poetries.work/gitee/2019/11/13.png)

新加入的对象都会存放到对象区域，当对象区域快被写满时，就需要执行一次垃圾清理操作。

在垃圾回收过程中，首先要对对象区域中的垃圾做标记；标记完成之后，就进入垃圾清理阶段，副垃圾回收器会把这些存活的对象复制到空闲区域中，同时它还会把这些对象有序地排列起来，所以这个复制过程，也就相当于完成了内存整理操作，复制后空闲区域就没有内存碎片了。

完成复制后，对象区域与空闲区域进行角色翻转，也就是原来的对象区域变成空闲区域，原来的空闲区域变成了对象区域。这样就完成了垃圾对象的回收操作，同时这种角色翻转的操作还能让新生代中的这两块区域无限重复使用下去。

由于新生代中采用的 Scavenge 算法，所以每次执行清理操作时，都需要将存活的对象从对象区域复制到空闲区域。但复制操作需要时间成本，如果新生区空间设置得太大了，那么每次清理的时间就会过久，所以为了执行效率，一般新生区的空间会被设置得比较小。

也正是因为新生区的空间不大，所以很容易被存活的对象装满整个区域。为了解决这个问题，JavaScript 引擎采用了对象晋升策略，也就是经过两次垃圾回收依然还存活的对象，会被移动到老生区中。

**主垃圾回收器**

主垃圾回收器主要负责老生区中的垃圾回收。除了新生区中晋升的对象，一些大的对象会直接被分配到老生区。因此老生区中的对象有两个特点，一个是对象占用空间大，另一个是对象存活时间长。

由于老生区的对象比较大，若要在老生区中使用 Scavenge 算法进行垃圾回收，复制这些大的对象将会花费比较多的时间，从而导致回收执行效率不高，同时还会浪费一半的空间。因而，主垃圾回收器是采用标记 - 清除（Mark-Sweep）的算法进行垃圾回收的。下面我们来看看该算法是如何工作的。

首先是标记过程阶段。标记阶段就是从一组根元素开始，递归遍历这组根元素，在这个遍历过程中，能到达的元素称为活动对象，没有到达的元素就可以判断为垃圾数据。

比如最开始的那段代码，当 showName 函数执行退出之后，这段代码的调用栈和堆空间如下图所示：

![](https://s.poetries.work/gitee/2019/11/14.png)

从上图你可以大致看到垃圾数据的标记过程，当 showName 函数执行结束之后，ESP 向下移动，指向了 foo 函数的执行上下文，这时候如果遍历调用栈，是不会找到引用 1003 地址的变量，也就意味着 1003 这块数据为垃圾数据，被标记为红色。由于 1050 这块数据被变量 b 引用了，所以这块数据会被标记为活动对象。这就是大致的标记过程。

接下来就是垃圾的清除过程。它和副垃圾回收器的垃圾清除过程完全不同，你可以理解这个过程是清除掉红色标记数据的过程，可参考下图大致理解下其清除过程：

![](https://s.poetries.work/gitee/2019/11/15.png)

上面的标记过程和清除过程就是标记 - 清除算法，不过对一块内存多次执行标记 - 清除算法后，会产生大量不连续的内存碎片。而碎片过多会导致大对象无法分配到足够的连续内存，于是又产生了另外一种算法——标记 - 整理（Mark-Compact），这个标记过程仍然与标记 - 清除算法里的是一样的，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。你可以参考下图

![](https://s.poetries.work/gitee/2019/11/16.png)

**全停顿**

现在你知道了 V8 是使用副垃圾回收器和主垃圾回收器处理垃圾回收的，不过由于 JavaScript 是运行在主线程之上的，一旦执行垃圾回收算法，都需要将正在执行的 JavaScript 脚本暂停下来，待垃圾回收完毕后再恢复脚本执行。我们把这种行为叫做全停顿（Stop-The-World）。

比如堆中的数据有 1.5GB，V8 实现一次完整的垃圾回收需要 1 秒以上的时间，这也是由于垃圾回收而引起 JavaScript 线程暂停执行的时间，若是这样的时间花销，那么应用的性能和响应能力都会直线下降。主垃圾回收器执行一次完整的垃圾回收流程如下图所示：

![](https://s.poetries.work/gitee/2019/11/17.png)

在 V8 新生代的垃圾回收中，因其空间较小，且存活对象较少，所以全停顿的影响不大，但老生代就不一样了。如果在执行垃圾回收的过程中，占用主线程时间过久，就像上面图片展示的那样，花费了 200 毫秒，在这 200 毫秒内，主线程是不能做其他事情的。比如页面正在执行一个 JavaScript 动画，因为垃圾回收器在工作，就会导致这个动画在这 200 毫秒内无法执行的，这将会造成页面的卡顿现象。

为了降低老生代的垃圾回收而造成的卡顿，V8 将标记过程分为一个个的子标记过程，同时让垃圾回收标记和 JavaScript 应用逻辑交替进行，直到标记阶段完成，我们把这个算法称为增量标记（Incremental Marking）算法。如下图所示：

![](https://s.poetries.work/gitee/2019/11/18.png)

使用增量标记算法，可以把一个完整的垃圾回收任务拆分为很多小的任务，这些小的任务执行时间比较短，可以穿插在其他的 JavaScript 任务中间执行，这样当执行上述动画效果时，就不会让用户因为垃圾回收任务而感受到页面的卡顿了。

### Javascript垃圾回收方法

标记清除（mark and sweep）

> - 这是JavaScript最常见的垃圾回收方式，当变量进入执行环境的时候，比如函数中声明一个变量，垃圾回收器将其标记为“进入环境”，当变量离开环境的时候（函数执行结束）将其标记为“离开环境”
> - 垃圾回收器会在运行的时候给存储在内存中的所有变量加上标记，然后去掉环境中的变量以及被环境中变量所引用的变量（闭包），在这些完成之后仍存在标记的就是要删除的变量了
> - 先所有都加上标记，再把环境中引用到的变量去除标记。剩下的就是没用的了

引用计数(reference counting)

> 在低版本IE中经常会出现内存泄露，很多时候就是因为其采用引用计数方式进行垃圾回收。引用计数的策略是跟踪记录每个值被使用的次数，当声明了一个变量并将一个引用类型赋值给该变量的时候这个值的引用次数就加1，如果该变量的值变成了另外一个，则这个值得引用次数减1，当这个值的引用次数变为0的时 候，说明没有变量在使用，这个值没法被访问了，因此可以将其占用的空间回收，这样垃圾回收器会在运行的时候清理掉引用次数为0的值占用的空间

> 找出那些不再继续使用的变 量，然后释放其占用的内存。为此，垃圾收集器会按照固定的时间间隔(或代码执行中预定的收集时间)， 周期性地执行这一操作。

> 跟踪记录每 个值被引用的次数。清除引用次数为0的变量 ⚠️会有循环引用问题 。循环引用如果大量存在就会导致内存泄露。

### V8 的垃圾回收机制

**如何查看 V8 的内存使用情况**

使用 `process.memoryUsage()`,返回如下

```
{
  rss: 4935680,
  heapTotal: 1826816,
  heapUsed: 650472,
  external: 49879
}
```

> `heapTotal` 和 `heapUsed` 代表 `V8` 的内存使用情况。`external` 代表 `V8` 管理的，绑定到 Javascript 的 C++对象的内存使用情况。rss, 驻留集大小, 是给这个进程分配了多少物理内存(占总分配内存的一部分) 这些物理内存中包含堆，栈，和代码段。

**V8 的内存限制是多少，为什么 V8 这样设计**

> 64 位系统下是 `1.4GB`， 32 位系统下是 `0.7GB`。因为 `1.5GB`的垃圾回收堆内存，V8 需要花费 50 毫秒以上，做一次非增量式的垃圾回收甚至要 1 秒以上。这是垃圾回收中引起 Javascript 线程暂停执行的事件，在这样的花销下，应用的性能和影响力都会直线下降。

**V8 的内存分代和回收算法请简单讲一讲**

> 在 V8 中，主要将内存分为新生代和老生代两代。新生代中的对象存活时间较短的对象，老生代中的对象存活时间较长，或常驻内存的对象。

![](https://s.poetries.work/images/20210517092109.png)

**新生代**

> 新生代中的对象主要通过 Scavenge 算法进行垃圾回收。这是一种采用复制的方式实现的垃圾回收算法。它将堆内存一份为二，每一部分空间成为 semispace。在这两个 semispace 空间中，只有一个处于使用中，另一个处于闲置状态。处于使用状态的 semispace 空间称为 From 空间，处于闲置状态的空间称为 To 空间

![](https://s.poetries.work/images/20210517092136.png)

- 当开始垃圾回收的时候，会检查 From 空间中的存活对象，这些存活对象将被复制到 To 空间中，而非存活对象占用的空间将会被释放。完成复制后，From 空间和 To 空间发生角色对换。
- 应为新生代中对象的生命周期比较短，就比较适合这个算法。
- 当一个对象经过多次复制依然存活，它将会被认为是生命周期较长的对象。这种新生代中生命周期较长的对象随后会被移到老生代中。

**老生代**

> 老生代主要采取的是标记清除的垃圾回收算法。与 Scavenge 复制活着的对象不同，标记清除算法在标记阶段遍历堆中的所有对象，并标记活着的对象，只清理死亡对象。活对象在新生代中只占叫小部分，死对象在老生代中只占较小部分，这是为什么采用标记清除算法的原因

**标记清除算法的问题**

主要问题是每一次进行标记清除回收后，内存空间会出现不连续的状态

![](https://s.poetries.work/images/20210517092246.png)

- 这种内存碎片会对后续内存分配造成问题，很可能出现需要分配一个大对象的情况，这时所有的碎片空间都无法完成此次分配，就会提前触发垃圾回收，而这次回收是不必要的。
- 为了解决碎片问题，标记整理被提出来。就是在对象被标记死亡后，在整理的过程中，将活着的对象往一端移动，移动完成后，直接清理掉边界外的内存。

**哪些情况会造成 V8 无法立即回收内存**

闭包和全局变量

### 请谈一下内存泄漏是什么，以及常见内存泄漏的原因，和排查的方法

1. 什么是内存泄漏
- 内存泄漏(Memory Leak)指由于疏忽或错误造成程序未能释放已经不再使用的内存的情况。
- 如果内存泄漏的位置比较关键，那么随着处理的进行可能持有越来越多的无用内存，这些无用的内存变多会引起服务器响应速度变慢。
- 严重的情况下导致内存达到某个极限(可能是进程的上限，如 v8 的上限;也可能是系统可提供的内存上限)会使得应用程序崩溃。常见内存泄漏的原因 内存泄漏的几种情况:

全局变量

```
a = 10;
//未声明对象。
global.b = 11;
//全局变量引用
// 这种比较简单的原因，全局变量直接挂在 root 对象上，不会被清除掉。
```

闭包

```
function out() {
    const bigData = new Buffer(100);
    inner = function () {

    }
}
```

> 闭包会引用到父级函数中的变量，如果闭包未释放，就会导致内存泄漏。上面例子是 inner 直接挂在了 root 上，那么每次执行 out 函数所产生的 bigData 都不会释放，从而导致内存泄漏。需要注意的是，这里举得例子只是简单的将引用挂在全局对象上，实际的业务情况可能是挂在某个可以从 root 追溯到的对象上导致的

事件监听

> Node.js 的事件监听也可能出现的内存泄漏。例如对同一个事件重复监听，忘记移除(removeListener)，将造成内存泄漏。这种情况很容易在复用对象上添加事件时出现，所以事件重复监听可能收到如下警告

```
emitter.setMaxListeners() to increase limit
```

**排查方法想要定位内存泄漏，通常会有两种情况**

- 对于只要正常使用就可以重现的内存泄漏，这是很简单的情况只要在测试环境模拟就可以排查了。
- 对于偶然的内存泄漏，一般会与特殊的输入有关系。想稳定重现这种输入是很耗时的过程。如果不能通过代码的日志定位到这个特殊的输入，那么推荐去生产环境打印内存快照了。
- 需要注意的是，打印内存快照是很耗 CPU 的操作，可能会对线上业务造成影响。快照工具推荐使用 heapdump 用来保存内存快照，使用 devtool 来查看内存快照。
- 使用 heapdump 保存内存快照时，只会有 Node.js 环境中的对象，不会受到干扰(如果使用 node-inspector 的话，快照中会有前端的变量干扰)。

> PS：安装 heapdump 在某些 Node.js 版本上可能出错，建议使用 `npm install heapdump -target=Node.js` 版本来安装。 

### HTTP 常见的状态码有哪些？

![五大类 HTTP 状态码](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/6-%E4%BA%94%E5%A4%A7%E7%B1%BBHTTP%E7%8A%B6%E6%80%81%E7%A0%81.png)

`1xx` 类状态码属于**提示信息**，是协议处理中的一种中间状态，实际用到的比较少。

`2xx` 类状态码表示服务器**成功**处理了客户端的请求，也是我们最愿意看到的状态。

- 「**200 OK**」是最常见的成功状态码，表示一切正常。如果是非 `HEAD` 请求，服务器返回的响应头都会有 body 数据。

- 「**204 No Content**」也是常见的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。

- 「**206 Partial Content**」是应用于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，而是其中的一部分，也是服务器处理成功的状态。

`3xx` 类状态码表示客户端请求的资源发生了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是**重定向**。

- 「**301 Moved Permanently**」表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。

- 「**302 Found**」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。

301 和 302 都会在响应头里使用字段 `Location`，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。

- 「**304 Not Modified**」不具有跳转的含义，表示资源未修改，重定向已存在的缓冲文件，也称缓存重定向，也就是告诉客户端可以继续使用缓存资源，用于缓存控制。

`4xx` 类状态码表示客户端发送的**报文有误**，服务器无法处理，也就是错误码的含义。

- 「**400 Bad Request**」表示客户端请求的报文有错误，但只是个笼统的错误。

- 「**403 Forbidden**」表示服务器禁止访问资源，并不是客户端的请求出错。

- 「**404 Not Found**」表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。

`5xx` 类状态码表示客户端请求报文正确，但是**服务器处理时内部发生了错误**，属于服务器端的错误码。

- 「**500 Internal Server Error**」与 400 类型，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。

- 「**501 Not Implemented**」表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。

- 「**502 Bad Gateway**」通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。

- 「**503 Service Unavailable**」表示服务器当前很忙，暂时无法响应客户端，类似“网络服务正忙，请稍后重试”的意思。

### GET 和 POST 有什么区别？

根据 RFC 规范，**GET 的语义是从服务器获取指定的资源**，这个资源可以是静态的文本、页面、图片视频等。GET 请求的参数位置一般是写在 URL 中，URL 规定只能支持 ASCII，所以 GET 请求的参数只允许 ASCII 字符 ，而且浏览器会对 URL 的长度有限制（HTTP协议本身对 URL长度并没有做任何规定）。

比如，你打开我的文章，浏览器就会发送 GET 请求给服务器，服务器就会返回文章的所有文字及资源。

![GET 请求](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/12-Get%E8%AF%B7%E6%B1%82.png)

根据 RFC 规范，**POST 的语义是根据请求负荷（报文body）对指定的资源做出处理**，具体的处理方式视资源类型而不同。POST 请求携带数据的位置一般是写在报文 body 中，body 中的数据可以是任意格式的数据，只要客户端与服务端协商好即可，而且浏览器不会对 body 大小做限制。

比如，你在我文章底部，敲入了留言后点击「提交」（**暗示你们留言**），浏览器就会执行一次 POST 请求，把你的留言文字放进了报文 body 里，然后拼接好 POST 请求头，通过 TCP 协议发送给服务器。

![POST 请求](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/13-Post%E8%AF%B7%E6%B1%82.png)

![](C:\Users\mohaixiao\AppData\Roaming\marktext\images\2023-04-09-16-47-33-image.png)

### GET 和 POST 方法都是安全和幂等的吗？

先说明下安全和幂等的概念：

- 在 HTTP 协议里，所谓的「安全」是指请求方法不会「破坏」服务器上的资源。
- 所谓的「幂等」，意思是多次执行相同的操作，结果都是「相同」的。

如果从 RFC 规范定义的语义来看：

- **GET 方法就是安全且幂等的**，因为它是「只读」操作，无论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。所以，**可以对 GET 请求的数据做缓存，这个缓存可以做到浏览器本身上（彻底避免浏览器发请求），也可以做到代理上（如nginx），而且在浏览器中 GET 请求可以保存为书签**。
- **POST** 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是**不安全**的，且多次提交数据就会创建多个资源，所以**不是幂等**的。所以，**浏览器一般不会缓存 POST 请求，也不能把 POST 请求保存为书签**。

**小结**

GET 的语义是请求获取指定的资源。GET 方法是安全、幂等、可被缓存的。

POST 的语义是根据请求负荷（报文主体）对指定的资源做出处理，具体的处理方式视资源类型而不同。POST 不安全，不幂等，（大部分实现）不可缓存。

注意， 上面是从 RFC 规范定义的语义来分析的。

但是实际过程中，开发者不一定会按照 RFC 规范定义的语义来实现 GET 和 POST 方法。比如：

- 可以用 GET 方法实现新增或删除数据的请求，这样实现的 GET 方法自然就不是安全和幂等。
- 可以用 POST 方法实现查询数据的请求，这样实现的 POST 方法自然就是安全和幂等。

曾经有个笑话，有人写了个博客，删除博客用的是 GET 请求，他觉得没人访问就连鉴权都没做。然后 Google 服务器爬虫爬了一遍，他所有博文就没了。。。

如果「安全」放入概念是指信息是否会被泄漏的话，虽然 POST 用 body 传输数据，而 GET 用 URL 传输，这样数据会在浏览器地址拦容易看到，但是并不能说 GET 不如 POST 安全的。

因为 HTTP 传输的内容都是明文的，虽然在浏览器地址拦看不到 POST 提交的 body 数据，但是只要抓个包就都能看到了。

所以，要避免传输过程中数据被窃取，就要使用 HTTPS 协议，这样所有 HTTP 的数据都会被加密传输。

> GET 请求可以带 body 吗？

RFC 规范并没有规定 GET 请求不能带 body 的。理论上，任何请求都可以带 body 的。只是因为 RFC 规范定义的 GET 请求是获取资源，所以根据这个语义不需要用到 body。

另外，URL 中的查询参数也不是 GET 所独有的，POST 请求的 URL 中也可以有参数的。

### 请解释一下同源策略 SOP，为什么要有同源限制？

- 概念:同源策略是客户端脚本（尤其是Javascript）的重要的安全度量标准。它最早出自Netscape Navigator2.0，其目的是防止某个文档或脚本从多个不同源装载。这里的同源策略指的是：协议，域名，端口相同，同源策略是一种安全协议
- 指一段脚本只能读取来自同一来源的窗口和文档的属性

我对浏览器的同源政策的理解是，一个域下的 js 脚本在未经允许的情况下，不能够访问另一个域的内容。这里的同源的指的是两个域的协议、域名、端口号必须相同，否则则不属于同一个域。

| url                                                             | 同源  |
| --------------------------------------------------------------- | --- |
| [https://niconico.com(opens new window)](https://niconico.com/) | 基准  |
| https://niconico.com/spirit                                     | o   |
| https://sub.niconico.com/spirit                                 | x   |
| http://niconico.com/spirit                                      | x   |
| https://niconico.com:8080/spirit                                | x   |

**同源政策主要限制了三个方面**

第一个是当前域下的 js 脚本不能够访问其他域下的 cookie、localStorage 和 indexDB。

第二个是当前域下的 js 脚本不能够操作访问操作其他域下的 DOM。

第三个是当前域下 ajax 无法发送跨域请求。

**同源政策的目的**

主要是为了保证用户的信息安全，它只是对 js 脚本的一种限制，并不是对浏览器的限制，对于一般的 img、或者script 脚本请求都不会有跨域的限制，这是因为这些操作都不会通过响应结果来进行可能出现安全问题的操作。

**其实表面上 SOP 分两种情况：**

- 可以正常引用 iframe、图片等各种资源，**但是**限制对其内容进行操作

- 直接限制 ajax 请求，准确来说是**限制操作 ajax 响应结果**，**这会引起 CSRF**

> 但是，本质上这两条是一样的：总之，对于非同源的资源，浏览器可以“直接使用”，但是程序员和用户不可以对这些数据进行操作，杜绝某些居心不良的行为。这就是现代安全浏览器对用户的保护之一。

- 如果你说 SOP 就是“限制非同源资源的获取”，这不对，最简单的例子是引用图片、css、js 文件等资源的时候就允许跨域。
- 如果你说 SOP 就是“禁止跨域请求”，这也不对，本质上 SOP 并不是禁止跨域请求，而是在请求后拦截了请求的回应。

**为什么要有同源限制？**

- 我们举例说明：比如一个黑客程序，他利用Iframe把真正的银行登录页面嵌到他的页面上，当你使用真实的用户名，密码登录时，他的页面就可以通过Javascript读取到你的表单中input中的内容，这样用户名，密码就轻松到手了。

- 设想这样一种情况：A网站是一家银行，用户登录以后，又去浏览其他网站。如果其他网站可以读取A网站的 Cookie，会发生什么？
  
  很显然，如果 Cookie 包含隐私（比如存款总额），这些信息就会泄漏。更可怕的是，Cookie 往往用来保存用户的登录状态，如果用户没有退出登录，其他网站就可以冒充用户，为所欲为。因为浏览器同时还规定，提交表单不受同源政策的限制。
  
  由此可见，"同源政策"是必需的，否则 Cookie 可以共享，互联网就毫无安全可言了。

- 缺点
  
  - 现在网站的JS都会进行压缩，一些文件用了严格模式，而另一些没有。这时这些本来是严格模式的文件，被 merge后，这个串就到了文件的中间，不仅没有指示严格模式，反而在压缩后浪费了字节
  
  **下面是 3 个在实际应用中会遇到的例子：**
  
  - 使用 ajax 请求其他跨域 API
  - iframe 与父页面交流（如 DOM 或变量的获取）
  - 对跨域图片（例如来源于 `<img>` ）进行操作，在 canvas 操作图片的时候会遇到这个问题
  
  **如果没有了 SOP：**
  
  - `iframe` 里的机密信息被肆意读取
  - 更加肆意地进行 `CSRF`
  - 接口被第三方滥用

### 如何解决跨域问题？

相关知识点：

- 1. 通过 jsonp 跨域
- 2. document.domain + iframe 跨域
- 3. location.hash + iframe
- 4. window.name + iframe 跨域
- 5. postMessage 跨域
- 6. 跨域资源共享（CORS)
- 7. nginx 代理跨域
- 8. nodejs 中间件代理跨域
- 9. WebSocket 协议跨域

**对于 ajax**

- 使用 `JSONP`
- 后端进行 `CORS` 配置
- 后端反向代理
- 使用 `WebSocket`

**对于 iframe**

- 使用 `location.hash` 或 `window.name` 进行信息交流
- 使用 `postMessage`

浏览器同源策略与ajax

> 对于 ajax 请求，在获得数据之后你能肆意进行 js 操作。这时候虽然同源策略会阻止响应，但依然会发出请求。因为**执行响应拦截的是浏览器**而不是后端程序。事实上你的**请求已经发到服务器**并返回了结果，但是迫于安全策略，浏览器不允许你**继续进行 js 操作**，所以报出你熟悉的 `blocked by CORS policy: No 'Access-Control-Allow-Origin' header is present on the requested resource.`。

**所以再强调一次，同源策略不能作为防范 CSRF 的方法**。

不过**可以防范 CSRF 的例外**（预检请求）还是有的，浏览器并不是让所有请求都发送成功，上述情况仅限于简单请求

回答：

解决跨域的方法我们可以根据我们想要实现的目的来划分。

首先我们如果只是想要实现主域名下的不同子域名的跨域操作，我们可以使用设置 document.domain 来解决。

（1）将 document.domain 设置为主域名，来实现相同子域名的跨域操作，这个时候主域名下的 cookie 就能够被子域名所访问。同时如果文档中含有主域名相同，子域名不同的 iframe 的话，我们也可以对这个 iframe 进行操作。

如果是想要解决不同跨域窗口间的通信问题，比如说一个页面想要和页面的中的不同源的 iframe 进行通信的问题，我们可以使用 location.hash 或者 window.name 或者 postMessage 来解决。

（2）使用 location.hash 的方法，我们可以在主页面动态的修改 iframe 窗口的 hash 值，然后在 iframe 窗口里实现监听函数来实现这样一个单向的通信。因为在 iframe 是没有办法访问到不同源的父级窗口的，所以我们不能直接修改父级窗口的 hash 值来实现通信，我们可以在 iframe 中再加入一个 iframe ，这个 iframe 的内容是和父级页面同源的，所以我们可以 window.parent.parent 来修改最顶级页面的 src，以此来实现双向通信。

（3）使用 window.name 的方法，主要是基于同一个窗口中设置了 window.name 后不同源的页面也可以访问，所以不同源的子页面可以首先在 window.name 中写入数据，然后跳转到一个和父级同源的页面。这个时候级页面就可以访问同源的子页面中 window.name 中的数据了，这种方式的好处是可以传输的数据量大。

（4）使用 postMessage 来解决的方法，这是一个 h5 中新增的一个 api。通过它我们可以实现多窗口间的信息传递，通过获取到指定窗口的引用，然后调用 postMessage 来发送信息，在窗口中我们通过对 message 信息的监听来接收信息，以此来实现不同源间的信息交换。

如果是像解决 ajax 无法提交跨域请求的问题，我们可以使用 jsonp、cors、websocket 协议、服务器代理来解决问题。

（5）使用 jsonp 来实现跨域请求，它的主要原理是通过动态构建 script 标签来实现跨域请求，因为浏览器对 script 标签的引入没有跨域的访问限制 。通过在请求的 url 后指定一个回调函数，然后服务器在返回数据的时候，构建一个 json 数据的包装，这个包装就是回调函数，然后返回给前端，前端接收到数据后，因为请求的是脚本文件，所以会直接执行，这样我们先前定义好的回调函数就可以被调用，从而实现了跨域请求的处理。这种方式只能用于 get 请求。

（6）使用 CORS 的方式，CORS 是一个 W3C 标准，全称是"跨域资源共享"。CORS 需要浏览器和服务器同时支持。目前，所有浏览器都支持该功能，因此我们只需要在服务器端配置就行。浏览器将 CORS 请求分成两类：简单请求和非简单请求。对于简单请求，浏览器直接发出 CORS 请求。具体来说，就是会在头信息之中，增加一个 Origin 字段。Origin 字段用来说明本次请求来自哪个源。服务器根据这个值，决定是否同意这次请求。对于如果 Origin 指定的源，不在许可范围内，服务器会返回一个正常的 HTTP 回应。浏览器发现，这个回应的头信息没有包含 Access-Control-Allow-Origin 字段，就知道出错了，从而抛出一个错误，ajax 不会收到响应信息。如果成功的话会包含一些以 Access-Control- 开头的字段。

非简单请求，浏览器会先发出一次预检请求，来判断该域名是否在服务器的白名单中，如果收到肯定回复后才会发起请求。

（7）使用 websocket 协议，这个协议没有同源限制。

（8）使用服务器来代理跨域的访问请求，就是有跨域的请求操作时发送请求给后端，让后端代为请求，然后最后将获取的结果发返回。

详细资料可以参考：
[《前端常见跨域解决方案（全）》](https://segmentfault.com/a/1190000011145364) 
[《浏览器同源政策及其规避方法》](http://www.ruanyifeng.com/blog/2016/04/same-origin-policy.html) 
[《跨域，你需要知道的全在这里》](https://juejin.im/entry/59feae9df265da43094488f6) 
[《为什么 form 表单提交没有跨域问题，但 ajax 提交有跨域问题？》](https://www.zhihu.com/question/31592553)
[面试题：window.name有什么用？](https://www.bilibili.com/video/BV1JS4y1T7xY/?spm_id_from=333.337.search-card.all.click&vd_source=037b856144283671f89f562ed7eeb263)

[location.href与window.open()的用法与区别，你都知道吗？ - 掘金](https://juejin.cn/post/7020425677237125127)

### 什么是跨域资源共享 CORS

跨域是浏览器限制，跨域资源共享（Cross-origin resource sharing）也是服务器与浏览器协调的结果。

> 如果服务器设置了 CORS 相关配置，在返回浏览器的请求头会加上 `Access-Control-Allow-Origin`，浏览器看到这个字段的值与当前的源匹配，就会解锁跨域限制。

```
HTTP/1.1 200 OK
Date: Sun, 24 Apr 2016 12:43:39 GMT
Server: Apache
Access-Control-Allow-Origin: http://www.acceptmeplease.com
Keep-Alive: timeout=2, max=100
Connection: Keep-Alive
Content-Type: application/xml
Content-Length: 423
```

对于 CORS，请求分两种。

**简单请求**

- 请求方法使用 `GET`、`POST` 或 `HEAD`
- `Content-Type` 设为 `application/x-www-form-urlencoded`、`multipart/form-data` 或 `text/plain`

符合上面两个条件的都为 `CORS` 简单请求。简单请求都会直接发到服务器，会造成 `CSRF`。

**预检请求**

> 不符合简单请求要求的请求都需要先发送预检请求（Preflight Request）。浏览器会在真正请求前发送 OPTION 方法的请求向服务器询问当前源是否符合 CORS 目标，验证通过后才会发送正式请求。

例如**使用 application/json 传参的 POST 请求**就是非简单请求，会在预检中被拦截。

再例如使用 `PUT` 方法请求，也会发送预检请求。

上面提到的**可以防范 CSRF 的例外**，就是指预检请求。即使跨域成功请求预检，但真正请求并不能发出去，这就保证了 `CSRF` 无法成功。

**CORS 与 cookie**

- 与同域不同，用于跨域的 `CORS` 请求默认不发送 `Cookie` 和 `HTTP` 认证信息，前后端都要在配置中设定请求时带上 `cookie`。
- 这就是为什么在进行 `CORS` 请求时 `axios` 需要设置 `withCredentials: true`。

下面是 `node.js` 的后台 `koa` 框架的 CORS 设置：

```
/**
 * CORS middleware
 *
 * @param {Object} [options]
 *  - {String|Function(ctx)} origin `Access-Control-Allow-Origin`, default is request Origin header
 *  - {String|Array} allowMethods `Access-Control-Allow-Methods`, default is 'GET,HEAD,PUT,POST,DELETE,PATCH'
 *  - {String|Array} exposeHeaders `Access-Control-Expose-Headers`
 *  - {String|Array} allowHeaders `Access-Control-Allow-Headers`
 *  - {String|Number} maxAge `Access-Control-Max-Age` in seconds
 *  - {Boolean} credentials `Access-Control-Allow-Credentials`
 *  - {Boolean} keepHeadersOnError Add set headers to `err.header` if an error is thrown
 * @return {Function} cors middleware
 * @api public
 */
```

> 顺带一提，`Access-Control-Allow-Credentials` 设为 `true` 时，`Access-Control-Allow-Origin` 强制不能设为 `*`，为了安全，也是挺麻烦

### 密码安全

**加盐**

> 对于密码存储来说，必然是不能明文存储在数据库中的，否则一旦数据库泄露，会对用户造成很大的损失。并且不建议只对密码单纯通过加密算法加密，因为存在彩虹表的关系

- 通常需要对密码加盐，然后进行几次不同加密算法的加密

```
// 加盐也就是给原密码添加字符串，增加原密码长度
sha256(sha1(md5(salt + password + salt)))
```

> 但是加盐并不能阻止别人盗取账号，只能确保即使数据库泄露，也不会暴露用户的真实密码。一旦攻击者得到了用户的账号，可以通过暴力破解的方式破解密码。对于这种情况，通常使用验证码增加延时或者限制尝试次数的方式。并且一旦用户输入了错误的密码，也不能直接提示用户输错密码，而应该提示账号或密码错误

**前端加密**

> 虽然前端加密对于安全防护来说意义不大，但是在遇到中间人攻击的情况下，可以避免明文密码被第三方获取

### 什么是 Samesite Cookie 属性？

Samesite Cookie 表示同站 cookie，避免 cookie 被第三方所利用。

将 Samesite 设为 strict ，这种称为严格模式，表示这个 cookie 在任何情况下都不可能作为第三方 cookie。

将 Samesite 设为 Lax ，这种模式称为宽松模式，如果这个请求是个 GET 请求，并且这个请求改变了当前页面或者打开了新的页面，那么这个 cookie 可以作为第三方 cookie，其余情况下都不能作为第三方 cookie。

使用这种方法的缺点是，因为它不支持子域，所以子域没有办法与主域共享登录信息，每次转入子域的网站，都回重新登录。还有一个问题就是它的兼容性不够好。

[预测最近面试会考 Cookie 的 SameSite 属性](https://juejin.cn/post/6844904095711494151)

[腾讯三面：Cookie 的 SameSite 了解吧，那 SameParty 呢？](https://juejin.cn/post/7087206796351242248)

### 服务器代理转发时，该如何处理 cookie？cookle是不是同源才能用?如果非同源想要用cookie，比如我访问google.com想用baidu.com的cookie怎么用?

[前端Cookie手把手教程](https://www.bilibili.com/video/BV1uG4y1t7dm/?vd_source=037b856144283671f89f562ed7eeb263)

[前端CORS跨域手把手教程](https://www.bilibili.com/video/BV1M84y1v7qH/?spm_id_from=333.788&vd_source=037b856144283671f89f562ed7eeb263)

### 简单谈一下 cookie ？在set-cookie的时候有一些属性,了解吗?

我的理解是 cookie 是服务器提供的一种用于维护会话状态信息的数据，通过服务器发送到浏览器，浏览器保存在本地，当下一次有同源的请求时，将保存的 cookie 值添加到请求头部，发送给服务端。这可以用来实现记录用户登录状态等功能。cookie 一般可以存储 4k 大小的数据，并且只能够被同源的网页所共享访问。

服务器端可以使用 Set-Cookie 的响应头部来配置 cookie 信息。一条cookie 包括了9个属性值 name、value、expires、domain、path、secure、HttpOnly、SameSite、Priority。其中 name 和 value 分别是 cookie 的名字和值。expires 指定了 cookie 失效的时间，domain 是域名、path是路径，domain 和 path 一起限制了 cookie 能够被哪些 url 访问。secure 规定了 cookie 只能在确保安全的情况下传输，HttpOnly 规定了这个 cookie 只能被服务器访问，不能使用 js 脚本访问。SameSite 属性用来限制第三方 cookie，可以有效防止 CSRF 攻击，从而减少安全风险。Priority 是 chrome 的提案，定义了三种优先级，当 cookie 数量超出时低优先级的 cookie 会被优先清除。

在发生 xhr 的跨域请求的时候，即使是同源下的 cookie，也不会被自动添加到请求头部，除非显示地规定。

详细资料可以参考：

[《HTTP cookies》](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Cookies) 

[《聊一聊 cookie》](https://segmentfault.com/a/1190000004556040)

### 请你谈谈Cookie的弊端

> `cookie`虽然在持久保存客户端数据提供了方便，分担了服务器存储的负担，但还是有很多局限性的

- 每个特定的域名下最多生成`20`个`cookie`
- `IE6`或更低版本最多`20`个`cookie`
- `IE7`和之后的版本最后可以有`50`个`cookie`
- `Firefox`最多50个`cookie`
- `chrome`和`Safari`没有做硬性限制
- IE 和 Opera 会清理近期最少使用的 `cookie`，`Firefox` 会随机清理 `cookie`
- `cookie` 的最大大约为 `4096` 字节，为了兼容性，一般设置不超过 `4095` 字节
- 如果 `cookie` 被人拦截了，就可以取得所有的 `session` 信息

### 如何删除一个cookie

- 将时间设为当前时间往前一点

```
var date = new Date();

date.setDate(date.getDate() - 1);//真正的删除
```

> `setDate()`方法用于设置一个月的某一天

- `expires`的设置

```
document.cookie = 'user='+ encodeURIComponent('name')  + ';
expires = ' + new Date(0)
```

### cookie 如何防范 XSS 攻击

> XSS(跨站脚本攻击)是指攻击者在返回的 HTML 中嵌入 javascript 脚本，为了减轻这些 攻击，需要在 HTTP 头部配上，set-cookie

- `httpOnly` 这个属性可以防止 XSS,它会禁止 javascript 脚本来访问 `cookie`
- `secure`- 这个属性告诉浏览器仅在请求为 `https` 的时候发送 `cookie`

### 什么是 XSS 攻击？如何防范 XSS 攻击？

XSS 攻击指的是跨站脚本攻击，是一种代码注入攻击。攻击者通过在网站注入恶意脚本，使之在用户的浏览器上运行，从而盗取用户的信息如 cookie 等。

XSS 的本质是因为网站没有对恶意代码进行过滤，与正常的代码混合在一起了，浏览器没有办法分辨哪些脚本是可信的，从而导致了恶意代码的执行。

**XSS 一般分为存储型、反射型和 DOM 型**

存储型指的是恶意代码提交到了网站的数据库中，当用户请求数据的时候，服务器将其拼接为 HTML 后返回给了用户，从而导致了恶意代码的执行。

反射型指的是攻击者构建了特殊的 URL，当服务器接收到请求后，从 URL 中获取数据，拼接到 HTML 后返回，从而导致了恶意代码的执行。

DOM 型指的是攻击者构建了特殊的 URL，用户打开网站后，js 脚本从 URL 中获取数据，从而导致了恶意代码的执行。

**XSS 攻击的预防**

可以从两个方面入手，一个是恶意代码提交的时候，一个是浏览器执行恶意代码的时候。

对于第一个方面，如果我们对存入数据库的数据都进行的转义处理，但是一个数据可能在多个地方使用，有的地方可能不需要转义，由于我们没有办法判断数据最后的使用场景，所以直接在输入端进行恶意代码的处理，其实是不太可靠的。

因此我们可以从浏览器的执行来进行预防，一种是使用纯前端的方式，不用服务器端拼接后返回。另一种是对需要插入到 HTML 中的代码做好充分的转义。对于 DOM 型的攻击，主要是前端脚本的不可靠而造成的，我们对于数据获取渲染和字符串拼接的时候应该对可能出现的恶意代码情况进行判断。

还有一些方式，比如使用 CSP ，CSP 的本质是建立一个白名单，告诉浏览器哪些外部资源可以加载和执行，从而防止恶意代码的注入攻击。

还可以对一些敏感信息进行保护，比如 cookie 使用 http-only ，使得脚本无法获取。也可以使用验证码，避免脚本伪装成用户执行一些操作。

详细资料可以参考：

 [《前端安全系列（一）：如何防止 XSS 攻击？》](https://juejin.im/post/5bad9140e51d450e935c6d64)

### 什么是 CSP？

CSP 指的是内容安全策略，它的本质是建立一个白名单，告诉浏览器哪些外部资源可以加载和执行。我们只需要配置规则，如何拦截由浏览器自己来实现。

通常有两种方式来开启 CSP，一种是设置 HTTP 首部中的 Content-Security-Policy，一种是设置 meta 标签的方式 `<meta http-equiv="Content-Security-Policy">`

详细资料可以参考： 

[《内容安全策略（CSP）》](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/CSP)

 [《前端面试之道》](https://juejin.im/book/5bdc715fe51d454e755f75ef/section/5bdc721851882516c33430a2)

### 跨站请求伪造CSRF

> - `CSRF` 就是利用用户的登录态发起恶意请求
> - `CSRF（Cross-site request forgery）` 跨站请求伪造，是一种常见的攻击方式。是指 `A` 网站正常登陆后，`cookie` 正常保存登录信息，其他网站 B 通过某种方式调用 A 网站接口进行操作，`A` 的接口会在请求时会自动带上 `cookie`。

- 同源策略可以通过 `html` 标签加载资源，而且同源策略不阻止接口请求而是拦截请求结果，`CSRF` 恰恰占了这两个便宜。
- 对于 `GET` 请求，直接放到 `<img>` 就能神不知鬼不觉地请求跨域接口。
- 对于 `POST` 请求，很多例子都使用 `form` 提交：

```
<form action="<nowiki>http://bank.com/transfer.do</nowiki>" method="POST">
  <input type="hidden" name="acct" value="MARIA" />
  <input type="hidden" name="amount" value="100000" />
  <input type="submit" value="View my pictures" />
</form>
```

> **浏览器同源策略不能作为防范 CSRF 的方法** 浏览器允许这么做，归根到底就是因为**你无法用 js 直接操作获得的结果。**

**如何攻击**

> 假设网站中有一个通过 Get 请求提交用户评论的接口，那么攻击者就可以在钓鱼网站中加入一个图片，图片的地址就是评论接口

```
<img src="http://www.domain.com/xxx?comment='attack'"/>
```

![](https://s.poetries.work/images/20210506174602.png)

```
res.setHeader('Set-Cookie', `username=poetry2;sameSite = strict;path=/;httpOnly;expires=${getCookirExpires()}`)
```

> 在B网站，危险网站向A网站发起请求

```
<!DOCTYPE html>
<html>
  <body>
  <!-- 利用img自动发送请求 -->
    <img src="http://localhost:8000/api/user/login" />
  </body>
</html>
```

会带上A网站的cookie

![](https://s.poetries.work/images/20210506174856.png)

```
// 在A网站下发cookie的时候，加上sameSite=strict，这样B网站在发送A网站请求，不会自动带上A网站的cookie，保证了安全


// NAME=VALUE    赋予Cookie的名称及对应值
// expires=DATE  Cookie 的有效期
// path=PATH     赋予Cookie的名称及对应值
// domain=域名   作为 Cookie 适用对象的域名 （若不指定则默认为创建 Cookie 的服务器的域名） (一般不指定)
// Secure        仅在 HTTPS 安全通信时才会发送 Cookie
// HttpOnly      加以限制，使 Cookie 不能被 JavaScript 脚本访问
// SameSite      Lax|Strict|None  它允许您声明该Cookie是否仅限于第一方或者同一站点上下文

res.setHeader('Set-Cookie', `username=poetry;sameSite=strict;path=/;httpOnly;expires=${getCookirExpires()}`)
```

![](https://s.poetries.work/images/20210506175834.png)

**如何防御**

- `Get` 请求不对数据进行修改
- 不让第三方网站访问到用户 `Cookie`
- 阻止第三方网站请求接口
- 请求时附带验证信息，比如验证码或者 `token`
- `SameSite Cookies`: 只能当前域名的网站发出的http请求，携带这个`Cookie`。当然，由于这是新的cookie属性，在兼容性上肯定会有问题

> CSRF攻击，仅仅是利用了http携带cookie的特性进行攻击的，但是攻击站点还是无法得到被攻击站点的cookie。这个和XSS不同，XSS是直接通过拿到Cookie等信息进行攻击的

**在CSRF攻击中，就Cookie相关的特性：**

- http请求，会自动携带Cookie。
- 携带的cookie，还是http请求所在域名的cookie。

### CSRF怎么获取用户的登录态

> 攻击全称不需要获取cookie，只是在危险的网站欺骗用户去点击已登录的网站链接，利用已登录的网站的自动发送cookie达到目的。因为http请求都会带着请求目标域下的`cookie`的，向同一个服务器发请求时会带上浏览器保存的对于那个服务器的cookie，而不管你从哪个网站向目标网站发请求

cookie通常是不能跨域访问的，那问什么会有csrf攻击

**疑问：**

> csrf说用户访问了A网站，然后又访问恶意网站B, B中也发送请求到A，携带A站的cookie，这样就构成了csrf。 可是cookie好像是不支持跨域的吧？

**回答**

- 浏览器会依据加载的域名附带上对应域名`cookie`，又不是发送b站的`cookie`。
- 就是如果用户在`a`站登录了生成了授权的`cookie` 之类的，然后访问`b`站，b站故意构造请求a站的请求，如删除操作之类的，用`script`，`img`或者`iframe`之类的加载`a`站着个地址，浏览器会附带上`a`站此登录用户的授权`cookie`信息，这样就构成`crsf`，会删除掉当前用户的数据

总结

- `XSS`攻击: 注入恶意代码
  - `cookie` 设置 `httpOnly`
  - 转义页面上的输入内容和输出内容
- `CSRF`: 跨站请求伪造，防护:
  - `get`不修改数据
  - 不被第三方网站访问到用户的 `cookie`
  - 设置白名单，不被第三方网站请求
  - 请求校验

### 什么是 CSRF 攻击？如何防范 CSRF 攻击？

CSRF 攻击指的是跨站请求伪造攻击，攻击者诱导用户进入一个第三方网站，然后该网站向被攻击网站发送跨站请求。如果用户在被
攻击网站中保存了登录状态，那么攻击者就可以利用这个登录状态，绕过后台的用户验证，冒充用户向服务器执行一些操作。

CSRF 攻击的本质是利用了 cookie 会在同源请求中携带发送给服务器的特点，以此来实现用户的冒充。

**一般的 CSRF 攻击类型有三种：**

第一种是 GET 类型的 CSRF 攻击，比如在网站中的一个 img 标签里构建一个请求，当用户打开这个网站的时候就会自动发起提
交。

第二种是 POST 类型的 CSRF 攻击，比如说构建一个表单，然后隐藏它，当用户进入页面时，自动提交这个表单。

第三种是链接类型的 CSRF 攻击，比如说在 a 标签的 href 属性里构建一个请求，然后诱导用户去点击。

**CSRF 可以用下面几种方法来防护：**

第一种是同源检测的方法，服务器根据 http 请求头中 origin 或者 referer 信息来判断请求是否为允许访问的站点，从而对请求进行过滤。当 origin 或者 referer 信息都不存在的时候，直接阻止。这种方式的缺点是有些情况下 referer 可以被伪造。还有就是我们这种方法同时把搜索引擎的链接也给屏蔽了，所以一般网站会允许搜索引擎的页面请求，但是相应的页面请求这种请求方式也可能被攻击者给利用。

第二种方法是使用 CSRF Token 来进行验证，服务器向用户返回一个随机数 Token ，当网站再次发起请求时，在请求参数中加入服务器端返回的 token ，然后服务器对这个 token 进行验证。这种方法解决了使用 cookie 单一验证方式时，可能会被冒用的问题，但是这种方法存在一个缺点就是，我们需要给网站中的所有请求都添加上这个 token，操作比较繁琐。还有一个问题是一般不会只有一台网站服务器，如果我们的请求经过负载平衡转移到了其他的服务器，但是这个服务器的 session 中没有保留这个 token 的话，就没有办法验证了。这种情况我们可以通过改变 token 的构建方式来解决。

第三种方式使用双重 Cookie 验证的办法，服务器在用户访问网站页面时，向请求域名注入一个Cookie，内容为随机字符串，然后当用户再次向服务器发送请求的时候，从 cookie 中取出这个字符串，添加到 URL 参数中，然后服务器通过对 cookie 中的数据和参数中的数据进行比较，来进行验证。使用这种方式是利用了攻击者只能利用 cookie，但是不能访问获取 cookie 的特点。并且这种方法比 CSRF Token 的方法更加方便，并且不涉及到分布式访问的问题。这种方法的缺点是如果网站存在 XSS 漏洞的，那么这种方式会失效。同时这种方式不能做到子域名的隔离。

第四种方式是使用在设置 cookie 属性的时候设置 Samesite ，限制 cookie 不能作为被第三方使用，从而可以避免被攻击者利用。Samesite 一共有两种模式，一种是严格模式，在严格模式下 cookie 在任何情况下都不可能作为第三方 Cookie 使用，在宽松模式下，cookie 可以被请求是 GET 请求，且会发生页面跳转的请求所使用。

详细资料可以参考：

 [《前端安全系列之二：如何防止 CSRF 攻击？》](https://juejin.im/post/5bc009996fb9a05d0a055192) 

[《[ HTTP 趣谈] origin, referer 和 host 区别》](https://www.jianshu.com/p/1f9c71850299)

### HTTP请求中token、cookie、session有什么区别

**现代浏览器开始禁止第三方cookie**

- 和跨域限制不同，这里是：禁止网页引入第三方js设置`cookie`
- 打击第三方广告设置`cookie`
- 可以通过属性设置 `SameSite:Strict/Lax/None`

**cookie和session**

- HTTP 是一个无状态协议，因此 Cookie 的最大的作用就是存储 sessionId 用来唯一标识用 户,每次请求都要携带`cookie`,以帮助识别身份

- 服务端也可以向客户端`set-cookie`,`cookie`大小`4kb`,单个 `cookie` 保存的数据不能超过 `4K`，很多浏览器都限制一个站点最多保存 20 个 `cookie`

- 默认有跨域限制：不可跨域共享，不可跨域传递`cookie`（可通过设置`withCredential`跨域传递`cookie`）

- `HTML5`之前`cookie`常被用于本地存储,`HTML5`之后推荐使用`localStorage`和`sessionStorage`

- `cookie` 数据存放在客户的浏览器上，`session` 会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能 考虑到减轻服务器性能方面，应当使用 `COOKIE`

- `cookie` 不是很安全，别人可以分析存放在本地的 COOKIE 并进行 COOKIE 欺骗 考虑到安全应当使用 session

- `cookie`用于登录验证，存储用户表示（`userId`）,`session`在服务端，存储用户详细信息，和`cookie`信息一一对应,`cookie+session`是常见的登录验证解决方案

**token和cookie**

- `cookie`是`HTTP`规范（每次请求都会携带），而`token`是自定义传递
- `cookie`会默认被浏览器存储，而`token`需自己存储
- `token`默认没有跨域限制

![](https://s.poetries.work/uploads/2023/01/bea409a27a4e9ad2.png)

```
// 登录：用户名 密码
// 服务端set-cookie: userId=x1 把用户id传给浏览器存储在cookie中
// 下次请求直接带上cookie:userId=x1 服务端根据userId找到哪个用户的信息

// 服务端session集中存储所有的用户信息在缓存中
const session = {
  x1: {
    username:'xx1',
    email:'xx1'
  },
  x2: { // 当下次来了一个用户x2也记录x2的登录信息,同时x1也不会丢失
    username:'xx2',
    email:'xx2'
  },
}
```

**JWT(json web token)**

- 前端发起登录，后端验证成功后，返回一个加密的`token`
- 前端自行存储这个`token`（其他包含了用户信息，加密的）
- 以后访问服务端接口，都携带着这个`token`，作为用户信息

**session和jwt哪个更好？**

- **session的优点**
  - 用户信息存储在服务端，可快速封禁某个用户
  - 占用服务端内存，成本高
  - 多进程多服务器时不好同步，需要使用`redis`缓存
  - 默认有跨域限制
- **JWT的优点**
  - 不占用服务端内存，`token`存储在客户端浏览器
  - 多进程、多服务器不受影响
  - 没有跨域限制
  - 用户信息存储在客户端，无法快速封禁某用户（可以在服务端建立黑名单，也需要成本）
  - 万一服务端密钥被泄露，则用户信息全部丢失
  - `token`体积一般比`cookie`大，会增加请求的数据量
- 如严格管理用户信息（保密、快速封禁）推荐使用`session`
- 没有特殊要求，推荐使用`JWT`

[使用什么保持用户登录状态？Session 还是 Token？](https://www.bilibili.com/video/BV1s5411V75g/?spm_id_from=333.999.0.0&vd_source=037b856144283671f89f562ed7eeb263)

### cookie 和 token 都存放在 header 中，为什么不会劫持 token？

- 攻击者通过 xss 拿到用户的 cookie 然后就可以伪造 cookie 了
- 或者通过 csrf 在同个浏览器下面通过浏览器会自动带上 cookie 的特性在通过 用户网站-攻击者网站-攻击者请求用户网站的方式 浏览器会自动带上cookie
- 但是 token。不会被浏览器带上 问题 2 解决
- token 是放在 jwt 里面下发给客户端的 而且不一定存储在哪里 不能通过document.cookie 直接拿到，通过 jwt+ip 的方式 可以防止 被劫持 即使被劫持也是无效的 jwt

### 介绍下如何实现 token 加密

- jwt 举例：
  - 1. 需要一个 secret（随机数）
  - 2. 后端利用 secret 和加密算法(如：HMAC-SHA256)对 payload(如账号密码) 生成一个字符串(token)，返回前端
  - 3. 前端每次 request 在 header 中带上 token
  - 4. 后端用同样的算法解密 

### 如何实现SSO(Single Sign On)单点登录

- 单点登录的`本质就是在多个应用系统中共享登录状态`，如果用户的登录状态是记录在 `Session` 中的，要实现共享登录状态，就要先共享 `Session`

- 所以实现单点登录的关键在于，如何让 `Session ID`（或 `Token`）在多个域中共享

- **主域名相同，基于cookie实现单点登录**
  
  - `cookie`默认不可跨域共享，但有些情况下可设置跨域共享
  - 主域名相同，如`www.baidu.com`、`image.baidu.com`
  - 设置`cookie domain`为主域`baidu.com`，即可共享`cookie`
  - 主域名不同，则`cookie`无法共享。可使用`sso`技术方案来做

- **主域名不同，基于SSO技术方案实现**
  
  - 系统`A`、`B`、`SSO`域名都是独立的
  - 用户访问系统`A`，系统`A`重定向到`SSO`登录（登录页面在`SSO`）输入用户名密码提交到`SSO`，验证用户名密码，将登录状态写入`SSO`的`session`，同时将`token`作为参数返回给客户端
  - 客户端携带`token`去访问系统`A`，系统`A`携带`token`去`SSO`验证，`SSO`验证通过返回用户信息给系统`A`
  - 用户访问`B`系统，`B`系统没有登录，重定向到`SSO`获取`token`（由于`SSO`已经登录了，不需要重新登录认证，之前在`A`系统登录过）,拿着`token`去`B`系统，`B`系统拿着`token`去`SSO`里面换取用户信息
  - 整个所有用户的登录、用户信息的保存、用户的`token`验证，全部都在`SSO`第三方独立的服务中处理

![](https://s.poetries.work/uploads/2023/01/428ac761b592fbc1.png)

### JWT是干什么的?还有什么其他方式能实现JWT的类似功能吗?，JWT中使用到了什么加密算法？介绍一下SHA256加密过程?JWT的优缺点？

JWT (JSON Web Token) 是一种开放标准，用于在网络应用程序和服务之间安全地传输信息。它通常用于验证用户身份和授权访问。

除了JWT，还有类似功能的技术，如基于会话的认证和基于令牌的认证（例如OAuth和OpenID Connect）。但是，JWT比这些技术更轻量级，更易于使用，并且不需要在服务器端保留任何状态。

JWT使用的加密算法包括 HMAC、RSA 和 ECDSA。其中，SHA256是一种哈希函数，它将输入数据转换为固定长度的唯一输出。SHA256使用的过程包括初始化、消息填充、处理数据块和输出结果。

JWT的优点包括易于使用、轻量级、跨语言支持和可扩展性。缺点包括无法撤销令牌、需要额外处理重要数据保护等方面的安全性考虑、以及对客户端存储的依赖。

### 那些操作会造成内存泄漏？

> JavaScript 内存泄露指对象在不需要使用它时仍然存在，导致占用的内存不能使用或回收

- 未使用 `var` 声明的全局变量
- 闭包函数(`Closures`)
- 循环引用(两个对象相互引用)
- 控制台日志(`console.log`)
- 移除存在绑定事件的`DOM`元素(`IE`)
- `setTimeout` 的第一个参数使用字符串而非函数的话，会引发内存泄漏
- 垃圾回收器定期扫描对象，并计算引用了每个对象的其他对象的数量。如果一个对象的引用数量为 `0`（没有其他对象引用过该对象），或对该对象的惟一引用是循环的，那么该对象的内存即可回收

**避免策略**

- 减少不必要的全局变量，或者生命周期较长的对象，及时对无用的数据进行垃圾回收；
- 注意程序逻辑，避免“死循环”之类的 ；
- 避免创建过多的对象 原则：不用了的东西要及时归还。
- 减少层级过多的引用

MAC地址

网络层有哪些协议

http是应用层的协议，它传输层用的协议是什么？tcp协议，除了tcp还有什么？

tcp和udp的区别是什么？

udp用到的场景较多的是什么？

http状态码 500 200 304 404等

304的协商缓存，讲一下协商缓存？
